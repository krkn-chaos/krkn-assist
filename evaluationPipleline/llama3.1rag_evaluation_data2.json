{
  "items": [
    {
      "user_input": "What is the primary objective of the 'Pod Scenarios' feature within Krkn-hub on a Kubernetes/OpenShift cluster?",
      "generated_answer": "The primary objective of the 'Pod Scenarios' feature within Krkn-hub on a Kubernetes/OpenShift cluster is to disrupt a specified number of pods in a targeted namespace or label, and verify their recovery within a set timeout. The feature allows for customization of disruption settings such as count, timeout, and recovery time. It can be used to simulate pod failures and test the reliability of the cluster.",
      "retrieved_context": [
        "Shell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help",
        "Shell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy",
        "None \n None \nPod  Scenarios  using  Krkn  \nExample  Config  The  following  are  the  components  of  Kubernetes  for  which  a  basic  chaos  scenario  config  exists  \ntoday.\n \nkraken:    chaos_scenarios:      -  pod_disruption_scenarios:        -  path/to/scenario.yaml  \nCopy  You  can  then  create  the  scenario  file  with  the  following  contents:  \n#  yaml-language-server:  $schema=../plugin.schema.json  -  id:  kill-pods    config:      namespace_pattern:  ^kube-system$      label_selector:  k8s-app=kube-scheduler      krkn_pod_recovery_time:  120       \nCopy  Please  adjust  the  schema  reference  to  point  to  the  schema  file.  This  file  will  give  you  code  completion  and  documentation  for  the  available  options  in  your  IDE.  \nPod  Chaos  Scenarios  The  following  are  the  components  of  Kubernetes/OpenShift  for  which  a  basic  chaos  scenario  \nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario",
        "Shell \nDISRUPTION_COUNT  Number  of  pods  to  disrupt  \n1  \nKILL_TIMEOUT  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \n180  \nEXPECTED_RECOVERY_TIME  Fails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \n120  \nNote  Set  NAMESPACE  environment  variable  to  openshift-.*  to  pick  and  disrupt  pods  randomly  in  \nopenshift\n \nsystem\n \nnamespaces,\n \nthe\n \nDAEMON_MODE\n \ncan\n \nalso\n \nbe\n \nenabled\n \nto\n \ndisrupt\n \nthe\n \npods\n \nevery\n \nx\n \nseconds\n \nin\n \nthe\n \nbackground\n \nto\n \ncheck\n \nthe\n \nreliability.\n \nNote  In  case  of  using  custom  metrics  profile  or  alerts  profile  when  CAPTURE_METRICS  or  \nENABLE_ALERTS\n \nis\n \nenabled,\n \nmount\n \nthe\n \nmetrics\n \nprofile\n \nfrom\n \nthe\n \nhost\n \non\n \nwhich\n \nthe\n \ncontainer\n \nis\n \nrun\n \nusing\n \npodman/docker\n \nunder\n \n/home/krkn/kraken/config/metrics-aggregated.yaml\n \nand\n \n/home/krkn/kraken/config/alerts.\n For  example:"
      ],
      "reference_answer": "The primary objective of the 'Pod Scenarios' feature in Krkn-hub is to disrupt pods that match a specified label within a designated namespace on either a Kubernetes or OpenShift cluster, simulating chaos conditions."    },
    {
      "user_input": "How can Cerberus be integrated with Krkn-hub's pod scenarios to monitor the cluster and determine the success or failure of a chaos injection?",
      "generated_answer": "To integrate Cerberus with Krkn-hub's pod scenarios, refer to the Cerberus documentation and set the CERBERUS_ENABLED environment variable in the chaos injection container. Start Cerberus before injecting chaos and autoconnect it by setting the variable to true.",
      "retrieved_context": [
        "Shell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy",
        "Shell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help",
        "None \n None \nPod  Scenarios  using  Krkn  \nExample  Config  The  following  are  the  components  of  Kubernetes  for  which  a  basic  chaos  scenario  config  exists  \ntoday.\n \nkraken:    chaos_scenarios:      -  pod_disruption_scenarios:        -  path/to/scenario.yaml  \nCopy  You  can  then  create  the  scenario  file  with  the  following  contents:  \n#  yaml-language-server:  $schema=../plugin.schema.json  -  id:  kill-pods    config:      namespace_pattern:  ^kube-system$      label_selector:  k8s-app=kube-scheduler      krkn_pod_recovery_time:  120       \nCopy  Please  adjust  the  schema  reference  to  point  to  the  schema  file.  This  file  will  give  you  code  completion  and  documentation  for  the  available  options  in  your  IDE.  \nPod  Chaos  Scenarios  The  following  are  the  components  of  Kubernetes/OpenShift  for  which  a  basic  chaos  scenario  \nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario",
        "Shell \nDISRUPTION_COUNT  Number  of  pods  to  disrupt  \n1  \nKILL_TIMEOUT  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \n180  \nEXPECTED_RECOVERY_TIME  Fails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \n120  \nNote  Set  NAMESPACE  environment  variable  to  openshift-.*  to  pick  and  disrupt  pods  randomly  in  \nopenshift\n \nsystem\n \nnamespaces,\n \nthe\n \nDAEMON_MODE\n \ncan\n \nalso\n \nbe\n \nenabled\n \nto\n \ndisrupt\n \nthe\n \npods\n \nevery\n \nx\n \nseconds\n \nin\n \nthe\n \nbackground\n \nto\n \ncheck\n \nthe\n \nreliability.\n \nNote  In  case  of  using  custom  metrics  profile  or  alerts  profile  when  CAPTURE_METRICS  or  \nENABLE_ALERTS\n \nis\n \nenabled,\n \nmount\n \nthe\n \nmetrics\n \nprofile\n \nfrom\n \nthe\n \nhost\n \non\n \nwhich\n \nthe\n \ncontainer\n \nis\n \nrun\n \nusing\n \npodman/docker\n \nunder\n \n/home/krkn/kraken/config/metrics-aggregated.yaml\n \nand\n \n/home/krkn/kraken/config/alerts.\n For  example:"
      ],
      "reference_answer": "To integrate Cerberus, it must be started before injecting chaos. For the chaos injection container to auto-connect with Cerberus and enable monitoring for pass/fail evaluation, the `CERBERUS_ENABLED` environment variable must be set."    },
    {
      "user_input": "What is the standard Podman command structure for initiating a pod disruption scenario with Krkn-hub, including how to provide the kube config and enable host environment variables?",
      "generated_answer": "To initiate a pod disruption scenario with Krkn-hub using Podman, run the command:\n\n`podman run --name=<container_name> --net=host --env-host=true -v <path-to-kube-config>:/home/krkn/.kube/config:Z -d containers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios`\n\nSet environment variables using the `-e` option, e.g., `-e VARIABLE=value`.\n\nNote: The `--env-host` option is not available on remote Podman clients.",
      "retrieved_context": [
        "Shell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy",
        "Outputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy  \nNote  \u2013env-host:  This  option  is  not  available  with  the  remote  Podman  client,  including  Mac  and  \nWindows\n \n(excluding\n \nWSL2)\n \nmachines.\n \nWithout\n \nthe\n \n\u2013env-host\n \noption\n \nyou\u2019ll\n \nhave\n \nto\n \nset\n \neach\n \nenviornment\n \nvariable\n \non\n \nthe\n \npodman\n \ncommand\n \nline\n \nlike\n \n-e\n \n<VARIABLE>=<value>\n \n$  docker  run  $(./get_docker_params.sh)  --name=<container_name>  --net=host  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n OR   $  docker  run  -e  <VARIABLE>=<value>  --name=<container_name>  --net=host  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n  $  docker  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  docker  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #",
        "Shell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help",
        "None \n None \nPod  Scenarios  using  Krkn  \nExample  Config  The  following  are  the  components  of  Kubernetes  for  which  a  basic  chaos  scenario  config  exists  \ntoday.\n \nkraken:    chaos_scenarios:      -  pod_disruption_scenarios:        -  path/to/scenario.yaml  \nCopy  You  can  then  create  the  scenario  file  with  the  following  contents:  \n#  yaml-language-server:  $schema=../plugin.schema.json  -  id:  kill-pods    config:      namespace_pattern:  ^kube-system$      label_selector:  k8s-app=kube-scheduler      krkn_pod_recovery_time:  120       \nCopy  Please  adjust  the  schema  reference  to  point  to  the  schema  file.  This  file  will  give  you  code  completion  and  documentation  for  the  available  options  in  your  IDE.  \nPod  Chaos  Scenarios  The  following  are  the  components  of  Kubernetes/OpenShift  for  which  a  basic  chaos  scenario  \nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario"
      ],
      "reference_answer": "The standard Podman command is `podman run --name=<container_name> --net=host --env-host=true -v <path-to-kube-config>:/home/krkn/.kube/config:Z -d containers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios`. This command runs the scenario container, mounts the kube config, and uses `--env-host=true` to allow the container to access host environment variables."    },
    {
      "user_input": "After a Krkn-hub pod scenario has been initiated, what commands can be used with both Podman and Docker to monitor its ongoing logs and to retrieve its final exit code for pass/fail determination?",
      "generated_answer": "To monitor the ongoing logs and retrieve the final exit code for a Krkn-hub pod scenario, you can use the following commands with both Docker and Podman:\n\n* To stream logs: `docker logs -f <container_name or container_id>` or `podman logs -f <container_name or container_id>`\n* To get the exit code: `docker inspect <container-name or container-id> --format \"{{.State.ExitCode}}\"` or `podman inspect <container-name or container-id> --format \"{{.State.ExitCode}}\"`",
      "retrieved_context": [
        "Outputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy  \nNote  \u2013env-host:  This  option  is  not  available  with  the  remote  Podman  client,  including  Mac  and  \nWindows\n \n(excluding\n \nWSL2)\n \nmachines.\n \nWithout\n \nthe\n \n\u2013env-host\n \noption\n \nyou\u2019ll\n \nhave\n \nto\n \nset\n \neach\n \nenviornment\n \nvariable\n \non\n \nthe\n \npodman\n \ncommand\n \nline\n \nlike\n \n-e\n \n<VARIABLE>=<value>\n \n$  docker  run  $(./get_docker_params.sh)  --name=<container_name>  --net=host  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n OR   $  docker  run  -e  <VARIABLE>=<value>  --name=<container_name>  --net=host  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n  $  docker  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  docker  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #",
        "Shell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy",
        "Shell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help",
        "$  docker  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  docker  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy"
      ],
      "reference_answer": "To monitor ongoing logs, use `podman logs -f <container_name or container_id>` or `docker logs -f <container_name or container_id>`. To determine the final outcome (pass/fail), the exit code can be retrieved using `podman inspect <container-name or container_id> --format \"{{.State.ExitCode}}\"` or `docker inspect <container-name or container_id> --format \"{{.State.ExitCode}}\"`."    },
    {
      "user_input": "What is a significant limitation of the `--env-host` option when running Krkn-hub scenarios with Podman on certain client types, and how should environment variables be managed in such cases?",
      "generated_answer": "A significant limitation of the `--env-host` option when running Krkn-hub scenarios with Podman on certain client types, such as Mac and Windows (excluding WSL2), is that it is not available. To manage environment variables in such cases, you must set each variable on the podman command line like `-e <VARIABLE>=<value>`.",
      "retrieved_context": [
        "Outputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy  \nNote  \u2013env-host:  This  option  is  not  available  with  the  remote  Podman  client,  including  Mac  and  \nWindows\n \n(excluding\n \nWSL2)\n \nmachines.\n \nWithout\n \nthe\n \n\u2013env-host\n \noption\n \nyou\u2019ll\n \nhave\n \nto\n \nset\n \neach\n \nenviornment\n \nvariable\n \non\n \nthe\n \npodman\n \ncommand\n \nline\n \nlike\n \n-e\n \n<VARIABLE>=<value>\n \n$  docker  run  $(./get_docker_params.sh)  --name=<container_name>  --net=host  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n OR   $  docker  run  -e  <VARIABLE>=<value>  --name=<container_name>  --net=host  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n  $  docker  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  docker  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #",
        "the\n \nhost\n \non\n \nwhich\n \nthe\n \ncontainer\n \nis\n \nrun\n \nusing\n \npodman/docker\n \nunder\n \n/home/krkn/kraken/config/metrics-aggregated.yaml\n \nand\n \n/home/krkn/kraken/config/alerts.\n For  example:  \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-custom-metrics-profile>:/home/krkn/kraken/config/metrics-aggregated.yaml\n \n-v\n \n<path-to-custom-alerts-profile>:/home/krkn/kraken/config/alerts\n \n-v\n \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:container-scenarios\n \nCopy",
        "None \n None \nTip  Because  the  container  runs  with  a  non-root  user,  ensure  the  kube  config  is  globally  readable  \nbefore\n \nmounting\n \nit\n \nin\n \nthe\n \ncontainer.\n \nYou\n \ncan\n \nachieve\n \nthis\n \nwith\n \nthe\n \nfollowing\n \ncommands:\n \nkubectl\n \nconfig\n \nview\n \n--flatten\n \n>\n \n~/kubeconfig\n \n&&\n \nchmod\n \n444\n \n~/kubeconfig\n \n&&\n \ndocker\n \nrun\n \n$(./get_docker_params.sh)\n \n--name=<container_name>\n \n--net=host\n \n-v\n \n~kubeconfig:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:<scenario>\n \nSupported  parameters  The  following  environment  variables  can  be  set  on  the  host  running  the  container  to  tweak  the  \nscenario/faults\n \nbeing\n \ninjected:\n Example  if  \u2013env-host  is  used:  \nexport  <parameter_name>=<value>  \nOR  on  the  command  line  like  example:  \n-e  <VARIABLE>=<value>",
        "Shell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help"
      ],
      "reference_answer": "The `--env-host` option is not available with remote Podman clients, including those on Mac and Windows (excluding WSL2). In these situations, environment variables must be set individually on the Podman command line using the `-e <VARIABLE>=<value>` syntax for each variable."    },
    {
      "user_input": "Why is it crucial to adjust the permissions of the kube config file before mounting it into the Krkn-hub container, and what specific commands are recommended to achieve this?",
      "generated_answer": "It is crucial to adjust the permissions of the kube config file before mounting it into the Krkn-hub container because the container runs with a non-root user and requires globally readable access. To achieve this, use the commands `kubectl config view --flatten > ~/kubeconfig && chmod 444 ~/kubeconfig`. This ensures the kube config is accessible by the non-root user in the container.",
      "retrieved_context": [
        "None \n None \nTip  Because  the  container  runs  with  a  non-root  user,  ensure  the  kube  config  is  globally  readable  \nbefore\n \nmounting\n \nit\n \nin\n \nthe\n \ncontainer.\n \nYou\n \ncan\n \nachieve\n \nthis\n \nwith\n \nthe\n \nfollowing\n \ncommands:\n \nkubectl\n \nconfig\n \nview\n \n--flatten\n \n>\n \n~/kubeconfig\n \n&&\n \nchmod\n \n444\n \n~/kubeconfig\n \n&&\n \ndocker\n \nrun\n \n$(./get_docker_params.sh)\n \n--name=<container_name>\n \n--net=host\n \n-v\n \n~kubeconfig:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:<scenario>\n \nSupported  parameters  The  following  environment  variables  can  be  set  on  the  host  running  the  container  to  tweak  the  \nscenario/faults\n \nbeing\n \ninjected:\n Example  if  \u2013env-host  is  used:  \nexport  <parameter_name>=<value>  \nOR  on  the  command  line  like  example:  \n-e  <VARIABLE>=<value>",
        "Shell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy",
        "the\n \nhost\n \non\n \nwhich\n \nthe\n \ncontainer\n \nis\n \nrun\n \nusing\n \npodman/docker\n \nunder\n \n/home/krkn/kraken/config/metrics-aggregated.yaml\n \nand\n \n/home/krkn/kraken/config/alerts.\n For  example:  \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-custom-metrics-profile>:/home/krkn/kraken/config/metrics-aggregated.yaml\n \n-v\n \n<path-to-custom-alerts-profile>:/home/krkn/kraken/config/alerts\n \n-v\n \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:container-scenarios\n \nCopy",
        "Outputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy  \nNote  \u2013env-host:  This  option  is  not  available  with  the  remote  Podman  client,  including  Mac  and  \nWindows\n \n(excluding\n \nWSL2)\n \nmachines.\n \nWithout\n \nthe\n \n\u2013env-host\n \noption\n \nyou\u2019ll\n \nhave\n \nto\n \nset\n \neach\n \nenviornment\n \nvariable\n \non\n \nthe\n \npodman\n \ncommand\n \nline\n \nlike\n \n-e\n \n<VARIABLE>=<value>\n \n$  docker  run  $(./get_docker_params.sh)  --name=<container_name>  --net=host  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n OR   $  docker  run  -e  <VARIABLE>=<value>  --name=<container_name>  --net=host  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n  $  docker  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  docker  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #"
      ],
      "reference_answer": "It is crucial because the Krkn-hub container runs with a non-root user, requiring the kube config to be globally readable. This can be achieved by first flattening the config and saving it (`kubectl config view --flatten > ~/kubeconfig`), and then changing its permissions to `444` (`chmod 444 ~/kubeconfig`) before mounting."    },
    {
      "user_input": "How can environment variables be passed to a Krkn-hub scenario container to customize its behavior, detailing both the host-based and command-line methods?",
      "generated_answer": "Environment variables can be passed to a Krkn-hub scenario container in two ways:\n\n1. Using the `--env-host` option when running the container, which allows setting environment variables on the host.\n2. Passing individual environment variables on the command line using the `-e` flag, like this: `$ docker run -e VARIABLE=value ...`\n\nBoth methods can be used to customize the behavior of the Krkn-hub scenario container.",
      "retrieved_context": [
        "Outputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy  \nNote  \u2013env-host:  This  option  is  not  available  with  the  remote  Podman  client,  including  Mac  and  \nWindows\n \n(excluding\n \nWSL2)\n \nmachines.\n \nWithout\n \nthe\n \n\u2013env-host\n \noption\n \nyou\u2019ll\n \nhave\n \nto\n \nset\n \neach\n \nenviornment\n \nvariable\n \non\n \nthe\n \npodman\n \ncommand\n \nline\n \nlike\n \n-e\n \n<VARIABLE>=<value>\n \n$  docker  run  $(./get_docker_params.sh)  --name=<container_name>  --net=host  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n OR   $  docker  run  -e  <VARIABLE>=<value>  --name=<container_name>  --net=host  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n  $  docker  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  docker  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #",
        "None \n None \nTip  Because  the  container  runs  with  a  non-root  user,  ensure  the  kube  config  is  globally  readable  \nbefore\n \nmounting\n \nit\n \nin\n \nthe\n \ncontainer.\n \nYou\n \ncan\n \nachieve\n \nthis\n \nwith\n \nthe\n \nfollowing\n \ncommands:\n \nkubectl\n \nconfig\n \nview\n \n--flatten\n \n>\n \n~/kubeconfig\n \n&&\n \nchmod\n \n444\n \n~/kubeconfig\n \n&&\n \ndocker\n \nrun\n \n$(./get_docker_params.sh)\n \n--name=<container_name>\n \n--net=host\n \n-v\n \n~kubeconfig:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:<scenario>\n \nSupported  parameters  The  following  environment  variables  can  be  set  on  the  host  running  the  container  to  tweak  the  \nscenario/faults\n \nbeing\n \ninjected:\n Example  if  \u2013env-host  is  used:  \nexport  <parameter_name>=<value>  \nOR  on  the  command  line  like  example:  \n-e  <VARIABLE>=<value>",
        "Shell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help",
        "Shell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy"
      ],
      "reference_answer": "Environment variables can be passed by setting them on the host running the container using `export <parameter_name>=<value>` if the `--env-host` option is used. Alternatively, they can always be passed directly on the command line when running the container using the `-e <VARIABLE>=<value>` flag."    },
    {
      "user_input": "What is the function of the `NAMESPACE` parameter in Krkn-hub pod scenarios, and what is its default value, including its support for advanced matching?",
      "generated_answer": "The `NAMESPACE` parameter in Krkn-hub pod scenarios is used to specify the targeted namespace in the cluster, and it supports regular expressions. Its default value is `openshift-*`.",
      "retrieved_context": [
        "Shell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help",
        "Shell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy",
        "scenario/faults\n \nbeing\n \ninjected:\n Example  if  \u2013env-host  is  used:  \nexport  <parameter_name>=<value>  \nOR  on  the  command  line  like  example:  \n-e  <VARIABLE>=<value>   \nSee  list  of  variables  that  apply  to  all  scenarios  here that  can  be  used/set  in  addition  to  these  scenario  specific  variables  Parameter  Description  Default  \nNAMESPACE  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nopenshift-.*  \nPOD_LABEL  Label  of  the  pod(s)  to  target  \n\"\"  \nNAME_PATTERN  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \n.*",
        "None \n None \nPod  Scenarios  using  Krkn  \nExample  Config  The  following  are  the  components  of  Kubernetes  for  which  a  basic  chaos  scenario  config  exists  \ntoday.\n \nkraken:    chaos_scenarios:      -  pod_disruption_scenarios:        -  path/to/scenario.yaml  \nCopy  You  can  then  create  the  scenario  file  with  the  following  contents:  \n#  yaml-language-server:  $schema=../plugin.schema.json  -  id:  kill-pods    config:      namespace_pattern:  ^kube-system$      label_selector:  k8s-app=kube-scheduler      krkn_pod_recovery_time:  120       \nCopy  Please  adjust  the  schema  reference  to  point  to  the  schema  file.  This  file  will  give  you  code  completion  and  documentation  for  the  available  options  in  your  IDE.  \nPod  Chaos  Scenarios  The  following  are  the  components  of  Kubernetes/OpenShift  for  which  a  basic  chaos  scenario  \nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario"
      ],
      "reference_answer": "The `NAMESPACE` parameter specifies the targeted namespace(s) within the cluster where the pod disruption will occur. It supports regular expressions for flexible matching, and its default value is `openshift-.*`, which targets all OpenShift system namespaces."    },
    {
      "user_input": "Explain the interplay between the `POD_LABEL` and `NAME_PATTERN` parameters in determining which pods are targeted for disruption, and what their default behaviors are.",
      "generated_answer": "Here is the explanation of the interplay between `POD_LABEL` and `NAME_PATTERN` parameters:\n\nThe `POD_LABEL` parameter specifies a label of the pod(s) to target, while the `NAME_PATTERN` parameter is used when `POD_LABEL` is not specified. It's a regex pattern to match pods in the namespace. If `POD_LABEL` is specified, it takes precedence over `NAME_PATTERN`.",
      "retrieved_context": [
        "Shell \nDISRUPTION_COUNT  Number  of  pods  to  disrupt  \n1  \nKILL_TIMEOUT  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \n180  \nEXPECTED_RECOVERY_TIME  Fails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \n120  \nNote  Set  NAMESPACE  environment  variable  to  openshift-.*  to  pick  and  disrupt  pods  randomly  in  \nopenshift\n \nsystem\n \nnamespaces,\n \nthe\n \nDAEMON_MODE\n \ncan\n \nalso\n \nbe\n \nenabled\n \nto\n \ndisrupt\n \nthe\n \npods\n \nevery\n \nx\n \nseconds\n \nin\n \nthe\n \nbackground\n \nto\n \ncheck\n \nthe\n \nreliability.\n \nNote  In  case  of  using  custom  metrics  profile  or  alerts  profile  when  CAPTURE_METRICS  or  \nENABLE_ALERTS\n \nis\n \nenabled,\n \nmount\n \nthe\n \nmetrics\n \nprofile\n \nfrom\n \nthe\n \nhost\n \non\n \nwhich\n \nthe\n \ncontainer\n \nis\n \nrun\n \nusing\n \npodman/docker\n \nunder\n \n/home/krkn/kraken/config/metrics-aggregated.yaml\n \nand\n \n/home/krkn/kraken/config/alerts.\n For  example:",
        "Shell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help",
        "scenario/faults\n \nbeing\n \ninjected:\n Example  if  \u2013env-host  is  used:  \nexport  <parameter_name>=<value>  \nOR  on  the  command  line  like  example:  \n-e  <VARIABLE>=<value>   \nSee  list  of  variables  that  apply  to  all  scenarios  here that  can  be  used/set  in  addition  to  these  scenario  specific  variables  Parameter  Description  Default  \nNAMESPACE  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nopenshift-.*  \nPOD_LABEL  Label  of  the  pod(s)  to  target  \n\"\"  \nNAME_PATTERN  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \n.*",
        "Shell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy"
      ],
      "reference_answer": "The `POD_LABEL` parameter specifies the label of the pod(s) to target, with a default of an empty string. If `POD_LABEL` is not specified, the `NAME_PATTERN` parameter is used instead to match pods within the `NAMESPACE` using a regex pattern. The `NAME_PATTERN` defaults to `.*`, meaning it will match all pods in the targeted namespace if no specific label is provided."    },
    {
      "user_input": "What do the `DISRUPTION_COUNT`, `KILL_TIMEOUT`, and `EXPECTED_RECOVERY_TIME` parameters control in a Krkn-hub pod scenario, and what are their default values?",
      "generated_answer": "The `DISRUPTION_COUNT`, `KILL_TIMEOUT`, and `EXPECTED_RECOVERY_TIME` parameters control the number of pods to disrupt, the timeout to wait for target pods to be removed, and the expected recovery time after disruption. Their default values are 1, 180 seconds, and 120 seconds, respectively. These parameters can be set when running a Krkn-hub pod scenario using `krknctl run pod-scenarios`.",
      "retrieved_context": [
        "Shell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help",
        "Shell \nDISRUPTION_COUNT  Number  of  pods  to  disrupt  \n1  \nKILL_TIMEOUT  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \n180  \nEXPECTED_RECOVERY_TIME  Fails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \n120  \nNote  Set  NAMESPACE  environment  variable  to  openshift-.*  to  pick  and  disrupt  pods  randomly  in  \nopenshift\n \nsystem\n \nnamespaces,\n \nthe\n \nDAEMON_MODE\n \ncan\n \nalso\n \nbe\n \nenabled\n \nto\n \ndisrupt\n \nthe\n \npods\n \nevery\n \nx\n \nseconds\n \nin\n \nthe\n \nbackground\n \nto\n \ncheck\n \nthe\n \nreliability.\n \nNote  In  case  of  using  custom  metrics  profile  or  alerts  profile  when  CAPTURE_METRICS  or  \nENABLE_ALERTS\n \nis\n \nenabled,\n \nmount\n \nthe\n \nmetrics\n \nprofile\n \nfrom\n \nthe\n \nhost\n \non\n \nwhich\n \nthe\n \ncontainer\n \nis\n \nrun\n \nusing\n \npodman/docker\n \nunder\n \n/home/krkn/kraken/config/metrics-aggregated.yaml\n \nand\n \n/home/krkn/kraken/config/alerts.\n For  example:",
        "None \n None \nPod  Scenarios  using  Krkn  \nExample  Config  The  following  are  the  components  of  Kubernetes  for  which  a  basic  chaos  scenario  config  exists  \ntoday.\n \nkraken:    chaos_scenarios:      -  pod_disruption_scenarios:        -  path/to/scenario.yaml  \nCopy  You  can  then  create  the  scenario  file  with  the  following  contents:  \n#  yaml-language-server:  $schema=../plugin.schema.json  -  id:  kill-pods    config:      namespace_pattern:  ^kube-system$      label_selector:  k8s-app=kube-scheduler      krkn_pod_recovery_time:  120       \nCopy  Please  adjust  the  schema  reference  to  point  to  the  schema  file.  This  file  will  give  you  code  completion  and  documentation  for  the  available  options  in  your  IDE.  \nPod  Chaos  Scenarios  The  following  are  the  components  of  Kubernetes/OpenShift  for  which  a  basic  chaos  scenario  \nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario",
        "Shell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy"
      ],
      "reference_answer": "The `DISRUPTION_COUNT` parameter specifies the number of pods to disrupt, defaulting to `1`. The `KILL_TIMEOUT` parameter sets the maximum time (in seconds) to wait for target pods to be removed, defaulting to `180`. The `EXPECTED_RECOVERY_TIME` parameter defines the timeout (in seconds) for disrupted pods to recover, defaulting to `120`, and the scenario fails if recovery doesn't occur within this period."    },
    {
      "user_input": "Beyond specific namespace targeting, how can the `NAMESPACE` environment variable be configured to randomly disrupt pods in OpenShift system namespaces, and what additional mode can be enabled for continuous reliability testing?",
      "generated_answer": "The `NAMESPACE` environment variable can be configured to randomly disrupt pods in OpenShift system namespaces by setting it to \"openshift-.*\". Additionally, the `DAEMON_MODE` can be enabled for continuous reliability testing. This mode allows disrupting pods every x seconds in the background to check cluster reliability.",
      "retrieved_context": [
        "Shell \nDISRUPTION_COUNT  Number  of  pods  to  disrupt  \n1  \nKILL_TIMEOUT  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \n180  \nEXPECTED_RECOVERY_TIME  Fails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \n120  \nNote  Set  NAMESPACE  environment  variable  to  openshift-.*  to  pick  and  disrupt  pods  randomly  in  \nopenshift\n \nsystem\n \nnamespaces,\n \nthe\n \nDAEMON_MODE\n \ncan\n \nalso\n \nbe\n \nenabled\n \nto\n \ndisrupt\n \nthe\n \npods\n \nevery\n \nx\n \nseconds\n \nin\n \nthe\n \nbackground\n \nto\n \ncheck\n \nthe\n \nreliability.\n \nNote  In  case  of  using  custom  metrics  profile  or  alerts  profile  when  CAPTURE_METRICS  or  \nENABLE_ALERTS\n \nis\n \nenabled,\n \nmount\n \nthe\n \nmetrics\n \nprofile\n \nfrom\n \nthe\n \nhost\n \non\n \nwhich\n \nthe\n \ncontainer\n \nis\n \nrun\n \nusing\n \npodman/docker\n \nunder\n \n/home/krkn/kraken/config/metrics-aggregated.yaml\n \nand\n \n/home/krkn/kraken/config/alerts.\n For  example:",
        "scenario/faults\n \nbeing\n \ninjected:\n Example  if  \u2013env-host  is  used:  \nexport  <parameter_name>=<value>  \nOR  on  the  command  line  like  example:  \n-e  <VARIABLE>=<value>   \nSee  list  of  variables  that  apply  to  all  scenarios  here that  can  be  used/set  in  addition  to  these  scenario  specific  variables  Parameter  Description  Default  \nNAMESPACE  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nopenshift-.*  \nPOD_LABEL  Label  of  the  pod(s)  to  target  \n\"\"  \nNAME_PATTERN  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \n.*",
        "Shell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help",
        "Shell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy"
      ],
      "reference_answer": "The `NAMESPACE` environment variable can be set to `openshift-.*` to randomly select and disrupt pods within OpenShift system namespaces. For continuous reliability testing, `DAEMON_MODE` can be enabled to disrupt pods every 'x' seconds in the background."    },
    {
      "user_input": "When `CAPTURE_METRICS` or `ENABLE_ALERTS` are active, how should custom metrics and alerts profiles be provided to the Krkn-hub container, including the specific internal paths for mounting?",
      "generated_answer": "When `CAPTURE_METRICS` or `ENABLE_ALERTS` are active, custom metrics and alerts profiles should be provided to the Krkn-hub container by mounting the paths `/home/krkn/kraken/config/metrics-aggregated.yaml` and `/home/krkn/kraken/config/alerts`. For example, use the command: `$ podman run --name=<container_name> --net=host --env-host=true -v <path-to-custom-metrics-profile>:/home/krkn/kraken/config/metrics-aggregated.yaml -v <path-to-custom-alerts-profile>:/home/krkn/kraken/config/alerts ...`.",
      "retrieved_context": [
        "the\n \nhost\n \non\n \nwhich\n \nthe\n \ncontainer\n \nis\n \nrun\n \nusing\n \npodman/docker\n \nunder\n \n/home/krkn/kraken/config/metrics-aggregated.yaml\n \nand\n \n/home/krkn/kraken/config/alerts.\n For  example:  \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-custom-metrics-profile>:/home/krkn/kraken/config/metrics-aggregated.yaml\n \n-v\n \n<path-to-custom-alerts-profile>:/home/krkn/kraken/config/alerts\n \n-v\n \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:container-scenarios\n \nCopy",
        "Shell \nDISRUPTION_COUNT  Number  of  pods  to  disrupt  \n1  \nKILL_TIMEOUT  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \n180  \nEXPECTED_RECOVERY_TIME  Fails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \n120  \nNote  Set  NAMESPACE  environment  variable  to  openshift-.*  to  pick  and  disrupt  pods  randomly  in  \nopenshift\n \nsystem\n \nnamespaces,\n \nthe\n \nDAEMON_MODE\n \ncan\n \nalso\n \nbe\n \nenabled\n \nto\n \ndisrupt\n \nthe\n \npods\n \nevery\n \nx\n \nseconds\n \nin\n \nthe\n \nbackground\n \nto\n \ncheck\n \nthe\n \nreliability.\n \nNote  In  case  of  using  custom  metrics  profile  or  alerts  profile  when  CAPTURE_METRICS  or  \nENABLE_ALERTS\n \nis\n \nenabled,\n \nmount\n \nthe\n \nmetrics\n \nprofile\n \nfrom\n \nthe\n \nhost\n \non\n \nwhich\n \nthe\n \ncontainer\n \nis\n \nrun\n \nusing\n \npodman/docker\n \nunder\n \n/home/krkn/kraken/config/metrics-aggregated.yaml\n \nand\n \n/home/krkn/kraken/config/alerts.\n For  example:",
        "None \n None \nTip  Because  the  container  runs  with  a  non-root  user,  ensure  the  kube  config  is  globally  readable  \nbefore\n \nmounting\n \nit\n \nin\n \nthe\n \ncontainer.\n \nYou\n \ncan\n \nachieve\n \nthis\n \nwith\n \nthe\n \nfollowing\n \ncommands:\n \nkubectl\n \nconfig\n \nview\n \n--flatten\n \n>\n \n~/kubeconfig\n \n&&\n \nchmod\n \n444\n \n~/kubeconfig\n \n&&\n \ndocker\n \nrun\n \n$(./get_docker_params.sh)\n \n--name=<container_name>\n \n--net=host\n \n-v\n \n~kubeconfig:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:<scenario>\n \nSupported  parameters  The  following  environment  variables  can  be  set  on  the  host  running  the  container  to  tweak  the  \nscenario/faults\n \nbeing\n \ninjected:\n Example  if  \u2013env-host  is  used:  \nexport  <parameter_name>=<value>  \nOR  on  the  command  line  like  example:  \n-e  <VARIABLE>=<value>",
        "Shell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy"
      ],
      "reference_answer": "When `CAPTURE_METRICS` or `ENABLE_ALERTS` are active, custom profiles must be mounted from the host into the container using volume mounts. The custom metrics profile should be mounted to `/home/krkn/kraken/config/metrics-aggregated.yaml`, and the custom alerts profile to `/home/krkn/kraken/config/alerts`."    },
    {
      "user_input": "When executing a `pod-scenarios` run with `krknctl`, what are the different mechanisms available for precisely identifying the target pods for disruption, and how do they interact?",
      "generated_answer": "To precisely identify target pods for disruption in a `pod-scenarios` run with `krknctl`, you can use the following mechanisms:\n\n* `--namespace`: targets pods in a specific namespace (supports regex).\n* `--pod-label`: targets pods with a specific label.\n* `--name-pattern`: uses a regex pattern to match pods in a specified namespace.\n\nThese mechanisms can be combined or used separately to target specific pods for disruption.",
      "retrieved_context": [
        "Shell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help",
        "None \n None \nPod  Scenarios  using  Krkn  \nExample  Config  The  following  are  the  components  of  Kubernetes  for  which  a  basic  chaos  scenario  config  exists  \ntoday.\n \nkraken:    chaos_scenarios:      -  pod_disruption_scenarios:        -  path/to/scenario.yaml  \nCopy  You  can  then  create  the  scenario  file  with  the  following  contents:  \n#  yaml-language-server:  $schema=../plugin.schema.json  -  id:  kill-pods    config:      namespace_pattern:  ^kube-system$      label_selector:  k8s-app=kube-scheduler      krkn_pod_recovery_time:  120       \nCopy  Please  adjust  the  schema  reference  to  point  to  the  schema  file.  This  file  will  give  you  code  completion  and  documentation  for  the  available  options  in  your  IDE.  \nPod  Chaos  Scenarios  The  following  are  the  components  of  Kubernetes/OpenShift  for  which  a  basic  chaos  scenario  \nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario",
        "Shell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy",
        "Shell \nDISRUPTION_COUNT  Number  of  pods  to  disrupt  \n1  \nKILL_TIMEOUT  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \n180  \nEXPECTED_RECOVERY_TIME  Fails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \n120  \nNote  Set  NAMESPACE  environment  variable  to  openshift-.*  to  pick  and  disrupt  pods  randomly  in  \nopenshift\n \nsystem\n \nnamespaces,\n \nthe\n \nDAEMON_MODE\n \ncan\n \nalso\n \nbe\n \nenabled\n \nto\n \ndisrupt\n \nthe\n \npods\n \nevery\n \nx\n \nseconds\n \nin\n \nthe\n \nbackground\n \nto\n \ncheck\n \nthe\n \nreliability.\n \nNote  In  case  of  using  custom  metrics  profile  or  alerts  profile  when  CAPTURE_METRICS  or  \nENABLE_ALERTS\n \nis\n \nenabled,\n \nmount\n \nthe\n \nmetrics\n \nprofile\n \nfrom\n \nthe\n \nhost\n \non\n \nwhich\n \nthe\n \ncontainer\n \nis\n \nrun\n \nusing\n \npodman/docker\n \nunder\n \n/home/krkn/kraken/config/metrics-aggregated.yaml\n \nand\n \n/home/krkn/kraken/config/alerts.\n For  example:"
      ],
      "reference_answer": "To precisely identify target pods for disruption, users can leverage three parameters: `--namespace`, `--pod-label`, and `--name-pattern`. The `--namespace` parameter allows targeting pods within a specific namespace, supporting regular expressions, with a default of `openshift-*`. The `--pod-label` parameter targets pods based on a specific label, such as \"app=test\". If `--pod-label` is not specified, the `--name-pattern` parameter, which defaults to `.*`, is used as a regex pattern to match pods within the specified `--namespace`."    },
    {
      "user_input": "Describe the two critical timeout parameters in `krknctl run pod-scenarios` and explain their distinct roles in determining the scenario's outcome.",
      "generated_answer": "The two critical timeout parameters in `krknctl run pod-scenarios` are:\n\n* `--kill-timeout`: the time to wait for the target pod(s) to be removed in seconds (default 180)\n* `--expected-recovery-time`: the time within which a disrupted pod should recover, failing if it doesn't (default 120)\n\nThese parameters determine how long to wait for a pod's removal and recovery, respectively.",
      "retrieved_context": [
        "Shell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help",
        "None \n None \nPod  Scenarios  using  Krkn  \nExample  Config  The  following  are  the  components  of  Kubernetes  for  which  a  basic  chaos  scenario  config  exists  \ntoday.\n \nkraken:    chaos_scenarios:      -  pod_disruption_scenarios:        -  path/to/scenario.yaml  \nCopy  You  can  then  create  the  scenario  file  with  the  following  contents:  \n#  yaml-language-server:  $schema=../plugin.schema.json  -  id:  kill-pods    config:      namespace_pattern:  ^kube-system$      label_selector:  k8s-app=kube-scheduler      krkn_pod_recovery_time:  120       \nCopy  Please  adjust  the  schema  reference  to  point  to  the  schema  file.  This  file  will  give  you  code  completion  and  documentation  for  the  available  options  in  your  IDE.  \nPod  Chaos  Scenarios  The  following  are  the  components  of  Kubernetes/OpenShift  for  which  a  basic  chaos  scenario  \nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario",
        "Shell \nDISRUPTION_COUNT  Number  of  pods  to  disrupt  \n1  \nKILL_TIMEOUT  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \n180  \nEXPECTED_RECOVERY_TIME  Fails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \n120  \nNote  Set  NAMESPACE  environment  variable  to  openshift-.*  to  pick  and  disrupt  pods  randomly  in  \nopenshift\n \nsystem\n \nnamespaces,\n \nthe\n \nDAEMON_MODE\n \ncan\n \nalso\n \nbe\n \nenabled\n \nto\n \ndisrupt\n \nthe\n \npods\n \nevery\n \nx\n \nseconds\n \nin\n \nthe\n \nbackground\n \nto\n \ncheck\n \nthe\n \nreliability.\n \nNote  In  case  of  using  custom  metrics  profile  or  alerts  profile  when  CAPTURE_METRICS  or  \nENABLE_ALERTS\n \nis\n \nenabled,\n \nmount\n \nthe\n \nmetrics\n \nprofile\n \nfrom\n \nthe\n \nhost\n \non\n \nwhich\n \nthe\n \ncontainer\n \nis\n \nrun\n \nusing\n \npodman/docker\n \nunder\n \n/home/krkn/kraken/config/metrics-aggregated.yaml\n \nand\n \n/home/krkn/kraken/config/alerts.\n For  example:",
        "Shell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy"
      ],
      "reference_answer": "The two critical timeout parameters are `--kill-timeout` and `--expected-recovery-time`. The `--kill-timeout` parameter, defaulting to 180 seconds, specifies the maximum time to wait for the target pod(s) to be removed from the cluster. In contrast, the `--expected-recovery-time` parameter, defaulting to 120 seconds, dictates the maximum time allowed for a disrupted pod to recover. If a pod fails to recover within this `expected-recovery-time`, the entire scenario will be marked as a failure."    },
    {
      "user_input": "If a user wants to disrupt more than one pod in a `pod-scenarios` run, which parameter needs to be adjusted, and what is the default behavior if this parameter is not explicitly set?",
      "generated_answer": "To disrupt more than one pod in a `pod-scenarios` run, you need to adjust the `--disruption-count` parameter. If this parameter is not explicitly set, the default behavior is to disrupt only 1 pod.",
      "retrieved_context": [
        "Shell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help",
        "scenario/faults\n \nbeing\n \ninjected:\n Example  if  \u2013env-host  is  used:  \nexport  <parameter_name>=<value>  \nOR  on  the  command  line  like  example:  \n-e  <VARIABLE>=<value>   \nSee  list  of  variables  that  apply  to  all  scenarios  here that  can  be  used/set  in  addition  to  these  scenario  specific  variables  Parameter  Description  Default  \nNAMESPACE  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nopenshift-.*  \nPOD_LABEL  Label  of  the  pod(s)  to  target  \n\"\"  \nNAME_PATTERN  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \n.*",
        "None \n None \nPod  Scenarios  using  Krkn  \nExample  Config  The  following  are  the  components  of  Kubernetes  for  which  a  basic  chaos  scenario  config  exists  \ntoday.\n \nkraken:    chaos_scenarios:      -  pod_disruption_scenarios:        -  path/to/scenario.yaml  \nCopy  You  can  then  create  the  scenario  file  with  the  following  contents:  \n#  yaml-language-server:  $schema=../plugin.schema.json  -  id:  kill-pods    config:      namespace_pattern:  ^kube-system$      label_selector:  k8s-app=kube-scheduler      krkn_pod_recovery_time:  120       \nCopy  Please  adjust  the  schema  reference  to  point  to  the  schema  file.  This  file  will  give  you  code  completion  and  documentation  for  the  available  options  in  your  IDE.  \nPod  Chaos  Scenarios  The  following  are  the  components  of  Kubernetes/OpenShift  for  which  a  basic  chaos  scenario  \nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario",
        "Why  pod  scenarios  are  important:   \n \nUse  Cases  and  Importance  of  Pod-Level  Chaos  Scenarios  \n1.  Single  Pod  Deletion  \u25cf  Use  Case:  Simulates  unplanned  deletion  of  a  single  pod  \u25cf  Why  It's  Important:  Validates  whether  the  ReplicaSet  or  Deployment  automatically  \ncreates\n \na\n \nreplacement.\n \u25cf  Customer  Impact:  Ensures  continuous  service  even  if  a  pod  unexpectedly  crashes.  \u25cf  Recovery  Timing:  Typically  <10  seconds  for  stateless  apps  (seen  in  Krkn  telemetry  \noutput).\n \u25cf  HA  Indicator:  Pod  is  automatically  rescheduled  and  becomes  Ready  without  manual  \nintervention.\n  Kubectl  delete  pod  <pod-name> delete  pod  <pod-name>  Kubectl  get  pods  #  watch  for  new  pods \n2.  Multiple  Pods  Deleted  Simultaneously  \u25cf  Use  Case:  Simulates  a  larger  failure  event,  such  as  a  node  crash  or  AZ  outage.  \u25cf  Why  It's  Important:  Tests  whether  the  system  has  enough  resources  and  policies  to  \nrecover"
      ],
      "reference_answer": "To disrupt more than one pod, the user needs to adjust the `--disruption-count` parameter. By default, if this parameter is not explicitly set, `krknctl run pod-scenarios` will only disrupt a single pod, as its default value is 1."    },
    {
      "user_input": "What is the default scope for targeting pods in a `krknctl run pod-scenarios` execution if no specific namespace, label, or name pattern is provided by the user?",
      "generated_answer": "If no specific namespace, label, or name pattern is provided by the user in a `krknctl run pod-scenarios` execution, the default scope targets pods with a namespace of `openshift-*`. This is specified under the `--namespace` parameter.",
      "retrieved_context": [
        "Shell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help",
        "scenario/faults\n \nbeing\n \ninjected:\n Example  if  \u2013env-host  is  used:  \nexport  <parameter_name>=<value>  \nOR  on  the  command  line  like  example:  \n-e  <VARIABLE>=<value>   \nSee  list  of  variables  that  apply  to  all  scenarios  here that  can  be  used/set  in  addition  to  these  scenario  specific  variables  Parameter  Description  Default  \nNAMESPACE  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nopenshift-.*  \nPOD_LABEL  Label  of  the  pod(s)  to  target  \n\"\"  \nNAME_PATTERN  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \n.*",
        "Shell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy",
        "None \n None \nPod  Scenarios  using  Krkn  \nExample  Config  The  following  are  the  components  of  Kubernetes  for  which  a  basic  chaos  scenario  config  exists  \ntoday.\n \nkraken:    chaos_scenarios:      -  pod_disruption_scenarios:        -  path/to/scenario.yaml  \nCopy  You  can  then  create  the  scenario  file  with  the  following  contents:  \n#  yaml-language-server:  $schema=../plugin.schema.json  -  id:  kill-pods    config:      namespace_pattern:  ^kube-system$      label_selector:  k8s-app=kube-scheduler      krkn_pod_recovery_time:  120       \nCopy  Please  adjust  the  schema  reference  to  point  to  the  schema  file.  This  file  will  give  you  code  completion  and  documentation  for  the  available  options  in  your  IDE.  \nPod  Chaos  Scenarios  The  following  are  the  components  of  Kubernetes/OpenShift  for  which  a  basic  chaos  scenario  \nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario"
      ],
      "reference_answer": "If no specific targeting parameters are provided, the `krknctl run pod-scenarios` execution will default to targeting pods within any namespace matching the `openshift-*` regex pattern, as specified by the `--namespace` parameter's default. Furthermore, within these namespaces, it will match any pod name due to the `--name-pattern` defaulting to `.*` when `--pod-label` is not specified."    },
    {
      "user_input": "How can a user obtain a comprehensive list of all configurable options and their descriptions for the `krknctl run pod-scenarios` command?",
      "generated_answer": "To obtain a comprehensive list of all configurable options and their descriptions for the `krknctl run pod-scenarios` command, use the `--help` option with the command. This will display a list of available scenario options. Alternatively, you can also refer to the schema file mentioned in the example configuration for more detailed documentation on available options.",
      "retrieved_context": [
        "Shell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help",
        "None \n None \nPod  Scenarios  using  Krkn  \nExample  Config  The  following  are  the  components  of  Kubernetes  for  which  a  basic  chaos  scenario  config  exists  \ntoday.\n \nkraken:    chaos_scenarios:      -  pod_disruption_scenarios:        -  path/to/scenario.yaml  \nCopy  You  can  then  create  the  scenario  file  with  the  following  contents:  \n#  yaml-language-server:  $schema=../plugin.schema.json  -  id:  kill-pods    config:      namespace_pattern:  ^kube-system$      label_selector:  k8s-app=kube-scheduler      krkn_pod_recovery_time:  120       \nCopy  Please  adjust  the  schema  reference  to  point  to  the  schema  file.  This  file  will  give  you  code  completion  and  documentation  for  the  available  options  in  your  IDE.  \nPod  Chaos  Scenarios  The  following  are  the  components  of  Kubernetes/OpenShift  for  which  a  basic  chaos  scenario  \nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario",
        "Shell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy",
        "scenario/faults\n \nbeing\n \ninjected:\n Example  if  \u2013env-host  is  used:  \nexport  <parameter_name>=<value>  \nOR  on  the  command  line  like  example:  \n-e  <VARIABLE>=<value>   \nSee  list  of  variables  that  apply  to  all  scenarios  here that  can  be  used/set  in  addition  to  these  scenario  specific  variables  Parameter  Description  Default  \nNAMESPACE  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nopenshift-.*  \nPOD_LABEL  Label  of  the  pod(s)  to  target  \n\"\"  \nNAME_PATTERN  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \n.*"
      ],
      "reference_answer": "A user can obtain a comprehensive list of all available scenario options and their descriptions for the `krknctl run pod-scenarios` command by executing `krknctl run pod-scenarios --help`."    },
    {
      "user_input": "Differentiate between the 'Single Pod Deletion' and 'Multiple Pods Deleted Simultaneously' chaos scenarios regarding their simulated failure types and the primary customer impact each aims to validate or expose.",
      "generated_answer": "Here are the differences between 'Single Pod Deletion' and 'Multiple Pods Deleted Simultaneously' chaos scenarios:\n\n**Single Pod Deletion**: Simulates unplanned deletion of a single pod, validating whether ReplicaSet or Deployment automatically creates a replacement. The primary customer impact is ensuring continuous service even if a pod unexpectedly crashes.\n\n**Multiple Pods Deleted Simultaneously**: Simulates a larger failure event, such as a node crash or AZ outage, testing the system's ability to recover from a cluster-level failure with multiple pods deleted at once.",
      "retrieved_context": [
        "Why  pod  scenarios  are  important:   \n \nUse  Cases  and  Importance  of  Pod-Level  Chaos  Scenarios  \n1.  Single  Pod  Deletion  \u25cf  Use  Case:  Simulates  unplanned  deletion  of  a  single  pod  \u25cf  Why  It's  Important:  Validates  whether  the  ReplicaSet  or  Deployment  automatically  \ncreates\n \na\n \nreplacement.\n \u25cf  Customer  Impact:  Ensures  continuous  service  even  if  a  pod  unexpectedly  crashes.  \u25cf  Recovery  Timing:  Typically  <10  seconds  for  stateless  apps  (seen  in  Krkn  telemetry  \noutput).\n \u25cf  HA  Indicator:  Pod  is  automatically  rescheduled  and  becomes  Ready  without  manual  \nintervention.\n  Kubectl  delete  pod  <pod-name> delete  pod  <pod-name>  Kubectl  get  pods  #  watch  for  new  pods \n2.  Multiple  Pods  Deleted  Simultaneously  \u25cf  Use  Case:  Simulates  a  larger  failure  event,  such  as  a  node  crash  or  AZ  outage.  \u25cf  Why  It's  Important:  Tests  whether  the  system  has  enough  resources  and  policies  to  \nrecover",
        "Shell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help",
        "Shell \nDISRUPTION_COUNT  Number  of  pods  to  disrupt  \n1  \nKILL_TIMEOUT  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \n180  \nEXPECTED_RECOVERY_TIME  Fails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \n120  \nNote  Set  NAMESPACE  environment  variable  to  openshift-.*  to  pick  and  disrupt  pods  randomly  in  \nopenshift\n \nsystem\n \nnamespaces,\n \nthe\n \nDAEMON_MODE\n \ncan\n \nalso\n \nbe\n \nenabled\n \nto\n \ndisrupt\n \nthe\n \npods\n \nevery\n \nx\n \nseconds\n \nin\n \nthe\n \nbackground\n \nto\n \ncheck\n \nthe\n \nreliability.\n \nNote  In  case  of  using  custom  metrics  profile  or  alerts  profile  when  CAPTURE_METRICS  or  \nENABLE_ALERTS\n \nis\n \nenabled,\n \nmount\n \nthe\n \nmetrics\n \nprofile\n \nfrom\n \nthe\n \nhost\n \non\n \nwhich\n \nthe\n \ncontainer\n \nis\n \nrun\n \nusing\n \npodman/docker\n \nunder\n \n/home/krkn/kraken/config/metrics-aggregated.yaml\n \nand\n \n/home/krkn/kraken/config/alerts.\n For  example:",
        "config\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario \nKill  a  pod.  :heavy_check_mark:  \nEtcd Kills  a  single/multiple  etcd  replicas.  \n:heavy_check_mark:"
      ],
      "reference_answer": "The 'Single Pod Deletion' scenario simulates an unplanned, isolated failure of a single pod, primarily validating whether the ReplicaSet or Deployment automatically creates a replacement to ensure continuous service with minimal customer impact. In contrast, 'Multiple Pods Deleted Simultaneously' simulates a larger, more widespread failure event, such as a node crash or an Availability Zone outage. This scenario tests the system's ability to recover gracefully with sufficient resources and policies, as a failure of all pods belonging to a service in this scenario directly impacts user experience if not properly mitigated by distributed replicas."    },
    {
      "user_input": "Explain the significance of 'Pod Eviction' as a chaos scenario, detailing its typical triggers and the specific configurations that are crucial for ensuring zero customer impact during such an event.",
      "generated_answer": "Pod Eviction is a chaos scenario where Kubernetes itself triggers an eviction of pods during node upgrades or scaling down. The significance of this scenario is to ensure that pods are evicted gracefully and restarted elsewhere without impacting customers, with zero customer impact if readiness/liveness probes and PDBs are correctly configured. Crucial configurations include proper readiness/liveness probe settings and Pod Disruption Budget (PDB) policies.",
      "retrieved_context": [
        "Why  pod  scenarios  are  important:   \n \nUse  Cases  and  Importance  of  Pod-Level  Chaos  Scenarios  \n1.  Single  Pod  Deletion  \u25cf  Use  Case:  Simulates  unplanned  deletion  of  a  single  pod  \u25cf  Why  It's  Important:  Validates  whether  the  ReplicaSet  or  Deployment  automatically  \ncreates\n \na\n \nreplacement.\n \u25cf  Customer  Impact:  Ensures  continuous  service  even  if  a  pod  unexpectedly  crashes.  \u25cf  Recovery  Timing:  Typically  <10  seconds  for  stateless  apps  (seen  in  Krkn  telemetry  \noutput).\n \u25cf  HA  Indicator:  Pod  is  automatically  rescheduled  and  becomes  Ready  without  manual  \nintervention.\n  Kubectl  delete  pod  <pod-name> delete  pod  <pod-name>  Kubectl  get  pods  #  watch  for  new  pods \n2.  Multiple  Pods  Deleted  Simultaneously  \u25cf  Use  Case:  Simulates  a  larger  failure  event,  such  as  a  node  crash  or  AZ  outage.  \u25cf  Why  It's  Important:  Tests  whether  the  system  has  enough  resources  and  policies  to  \nrecover",
        "None \n None \nPod  Scenarios  using  Krkn  \nExample  Config  The  following  are  the  components  of  Kubernetes  for  which  a  basic  chaos  scenario  config  exists  \ntoday.\n \nkraken:    chaos_scenarios:      -  pod_disruption_scenarios:        -  path/to/scenario.yaml  \nCopy  You  can  then  create  the  scenario  file  with  the  following  contents:  \n#  yaml-language-server:  $schema=../plugin.schema.json  -  id:  kill-pods    config:      namespace_pattern:  ^kube-system$      label_selector:  k8s-app=kube-scheduler      krkn_pod_recovery_time:  120       \nCopy  Please  adjust  the  schema  reference  to  point  to  the  schema  file.  This  file  will  give  you  code  completion  and  documentation  for  the  available  options  in  your  IDE.  \nPod  Chaos  Scenarios  The  following  are  the  components  of  Kubernetes/OpenShift  for  which  a  basic  chaos  scenario  \nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario",
        "recover\n \ngracefully.\n \u25cf  Customer  Impact:  If  all  pods  of  a  service  fail,  user  experience  is  directly  impacted.  \u25cf  HA  Indicator:  Application  can  continue  functioning  from  other  replicas  across  \nzones/nodes.\n \n \n3.  Pod  Eviction  (Soft  Disruption)  \u25cf  Use  Case:  Triggered  by  Kubernetes  itself  during  node  upgrades  or  scaling  down.  \u25cf  Why  It's  Important:  Ensures  graceful  termination  and  restart  elsewhere  without  user  \nimpact.\n \u25cf  Customer  Impact:  Should  be  zero  if  readiness/liveness  probes  and  PDBs  are  correctly  \nconfigured.\n \u25cf  HA  Indicator:  Rolling  disruption  does  not  take  down  the  whole  application.  \n \nHow  to  Know  If  It's  Highly  Available",
        "Shell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help"
      ],
      "reference_answer": "Pod Eviction is a significant chaos scenario because it simulates a 'soft disruption' triggered by Kubernetes itself, typically during routine operations like node upgrades or scaling down. Its importance lies in ensuring graceful termination and restart of pods elsewhere without user impact. For zero customer impact, it is crucial that readiness and liveness probes are correctly configured to manage pod health and traffic flow, and that Pod Disruption Budgets (PDBs) are in place to define the minimum number of available replicas, thereby ensuring that a rolling disruption does not take down the entire application."    },
    {
      "user_input": "What specific metrics and observations from Krkn telemetry are crucial for quantitatively assessing the high availability of an application after a chaos engineering run?",
      "generated_answer": "The specific metrics and observations from Krkn telemetry crucial for quantitatively assessing the high availability of an application after a chaos engineering run are recovery times, pod reschedule latency, and service downtime. These metrics can be found in the end-of-run data provided by Krkn Telemetry Indicators. The expected recovery time (120 seconds) is also a key metric to assess HA.",
      "retrieved_context": [
        "1.  Multiple  Replicas  Exist:  Confirmed  by  checking  kubectl  get  deploy and  seeing  >1  \nreplicas.\n 2.  Pods  Distributed  Across  Nodes/availability  zones:  Using  topologySpreadConstraints or  observing  pod  distribution  in  kubectl  get  pods  \n-o\n \nwide.  3.  Service  Uptime  Remains  Unaffected:  During  chaos  test,  verify  app  availability  (  \nsynthetic\n \nprobes,\n \nPrometheus\n \nalerts,\n \netc).\n 4.  Recovery  Is  Automatic:  No  manual  intervention  needed  to  restore  service.  5.  Krkn  Telemetry  Indicators:  End  of  run  data  includes  recovery  times,  pod  reschedule  \nlatency,\n \nand\n \nservice\n \ndowntime\n \nwhich\n \nare\n \nvital\n \nmetrics\n \nfor\n \nassessing\n \nHA.",
        "Shell \nDISRUPTION_COUNT  Number  of  pods  to  disrupt  \n1  \nKILL_TIMEOUT  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \n180  \nEXPECTED_RECOVERY_TIME  Fails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \n120  \nNote  Set  NAMESPACE  environment  variable  to  openshift-.*  to  pick  and  disrupt  pods  randomly  in  \nopenshift\n \nsystem\n \nnamespaces,\n \nthe\n \nDAEMON_MODE\n \ncan\n \nalso\n \nbe\n \nenabled\n \nto\n \ndisrupt\n \nthe\n \npods\n \nevery\n \nx\n \nseconds\n \nin\n \nthe\n \nbackground\n \nto\n \ncheck\n \nthe\n \nreliability.\n \nNote  In  case  of  using  custom  metrics  profile  or  alerts  profile  when  CAPTURE_METRICS  or  \nENABLE_ALERTS\n \nis\n \nenabled,\n \nmount\n \nthe\n \nmetrics\n \nprofile\n \nfrom\n \nthe\n \nhost\n \non\n \nwhich\n \nthe\n \ncontainer\n \nis\n \nrun\n \nusing\n \npodman/docker\n \nunder\n \n/home/krkn/kraken/config/metrics-aggregated.yaml\n \nand\n \n/home/krkn/kraken/config/alerts.\n For  example:",
        "Shell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy",
        "Shell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help"
      ],
      "reference_answer": "Krkn telemetry provides vital end-of-run data that is crucial for quantitatively assessing an application's high availability. Key indicators include recovery times, which measure how quickly services are restored post-disruption; pod reschedule latency, indicating the time taken for new pods to become ready and operational; and service downtime, which quantifies any periods of unavailability experienced by the application. These metrics collectively offer a precise measure of the system's resilience and its ability to recover automatically."    },
    {
      "user_input": "Beyond automatic recovery, what are the key architectural and operational indicators, as described in the text, that confirm an application is highly available in a Kubernetes environment?",
      "generated_answer": "The key architectural and operational indicators that confirm an application is highly available in a Kubernetes environment are: multiple replicas exist, pods distributed across nodes/availability zones, service uptime remains unaffected during chaos tests, recovery is automatic, and Kraken telemetry indicators show good performance metrics. These indicators ensure the application can continue functioning even if some replicas fail. They also guarantee zero customer impact and rolling disruption does not take down the whole application.",
      "retrieved_context": [
        "1.  Multiple  Replicas  Exist:  Confirmed  by  checking  kubectl  get  deploy and  seeing  >1  \nreplicas.\n 2.  Pods  Distributed  Across  Nodes/availability  zones:  Using  topologySpreadConstraints or  observing  pod  distribution  in  kubectl  get  pods  \n-o\n \nwide.  3.  Service  Uptime  Remains  Unaffected:  During  chaos  test,  verify  app  availability  (  \nsynthetic\n \nprobes,\n \nPrometheus\n \nalerts,\n \netc).\n 4.  Recovery  Is  Automatic:  No  manual  intervention  needed  to  restore  service.  5.  Krkn  Telemetry  Indicators:  End  of  run  data  includes  recovery  times,  pod  reschedule  \nlatency,\n \nand\n \nservice\n \ndowntime\n \nwhich\n \nare\n \nvital\n \nmetrics\n \nfor\n \nassessing\n \nHA.",
        "recover\n \ngracefully.\n \u25cf  Customer  Impact:  If  all  pods  of  a  service  fail,  user  experience  is  directly  impacted.  \u25cf  HA  Indicator:  Application  can  continue  functioning  from  other  replicas  across  \nzones/nodes.\n \n \n3.  Pod  Eviction  (Soft  Disruption)  \u25cf  Use  Case:  Triggered  by  Kubernetes  itself  during  node  upgrades  or  scaling  down.  \u25cf  Why  It's  Important:  Ensures  graceful  termination  and  restart  elsewhere  without  user  \nimpact.\n \u25cf  Customer  Impact:  Should  be  zero  if  readiness/liveness  probes  and  PDBs  are  correctly  \nconfigured.\n \u25cf  HA  Indicator:  Rolling  disruption  does  not  take  down  the  whole  application.  \n \nHow  to  Know  If  It's  Highly  Available",
        "Shell \nDISRUPTION_COUNT  Number  of  pods  to  disrupt  \n1  \nKILL_TIMEOUT  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \n180  \nEXPECTED_RECOVERY_TIME  Fails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \n120  \nNote  Set  NAMESPACE  environment  variable  to  openshift-.*  to  pick  and  disrupt  pods  randomly  in  \nopenshift\n \nsystem\n \nnamespaces,\n \nthe\n \nDAEMON_MODE\n \ncan\n \nalso\n \nbe\n \nenabled\n \nto\n \ndisrupt\n \nthe\n \npods\n \nevery\n \nx\n \nseconds\n \nin\n \nthe\n \nbackground\n \nto\n \ncheck\n \nthe\n \nreliability.\n \nNote  In  case  of  using  custom  metrics  profile  or  alerts  profile  when  CAPTURE_METRICS  or  \nENABLE_ALERTS\n \nis\n \nenabled,\n \nmount\n \nthe\n \nmetrics\n \nprofile\n \nfrom\n \nthe\n \nhost\n \non\n \nwhich\n \nthe\n \ncontainer\n \nis\n \nrun\n \nusing\n \npodman/docker\n \nunder\n \n/home/krkn/kraken/config/metrics-aggregated.yaml\n \nand\n \n/home/krkn/kraken/config/alerts.\n For  example:",
        "config\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario \nKill  a  pod.  :heavy_check_mark:  \nEtcd Kills  a  single/multiple  etcd  replicas.  \n:heavy_check_mark:"
      ],
      "reference_answer": "To confirm an application's high availability in a Kubernetes environment, several architectural and operational indicators are crucial. Architecturally, it's essential to verify that multiple replicas exist for deployments (e.g., `kubectl get deploy` showing >1 replicas) and that pods are distributed across different nodes or availability zones, often achieved using `topologySpreadConstraints` or observed via `kubectl get pods -o wide`. Operationally, during chaos tests, service uptime must remain unaffected, which can be verified through synthetic probes or Prometheus alerts, and crucially, recovery from disruptions must be entirely automatic, requiring no manual intervention."    },
    {
      "user_input": "How does the 'Single Pod Deletion' scenario specifically validate the resilience mechanisms of Kubernetes, and what is the expected recovery timing for stateless applications in this context?",
      "generated_answer": "The 'Single Pod Deletion' scenario validates the resilience mechanisms of Kubernetes by automatically creating a replacement pod, ensuring continuous service even if a pod unexpectedly crashes. The expected recovery timing for stateless applications in this context is typically less than 10 seconds. This is confirmed by Krkn telemetry output and indicates that the system has enough resources and policies to recover gracefully.",
      "retrieved_context": [
        "Why  pod  scenarios  are  important:   \n \nUse  Cases  and  Importance  of  Pod-Level  Chaos  Scenarios  \n1.  Single  Pod  Deletion  \u25cf  Use  Case:  Simulates  unplanned  deletion  of  a  single  pod  \u25cf  Why  It's  Important:  Validates  whether  the  ReplicaSet  or  Deployment  automatically  \ncreates\n \na\n \nreplacement.\n \u25cf  Customer  Impact:  Ensures  continuous  service  even  if  a  pod  unexpectedly  crashes.  \u25cf  Recovery  Timing:  Typically  <10  seconds  for  stateless  apps  (seen  in  Krkn  telemetry  \noutput).\n \u25cf  HA  Indicator:  Pod  is  automatically  rescheduled  and  becomes  Ready  without  manual  \nintervention.\n  Kubectl  delete  pod  <pod-name> delete  pod  <pod-name>  Kubectl  get  pods  #  watch  for  new  pods \n2.  Multiple  Pods  Deleted  Simultaneously  \u25cf  Use  Case:  Simulates  a  larger  failure  event,  such  as  a  node  crash  or  AZ  outage.  \u25cf  Why  It's  Important:  Tests  whether  the  system  has  enough  resources  and  policies  to  \nrecover",
        "recover\n \ngracefully.\n \u25cf  Customer  Impact:  If  all  pods  of  a  service  fail,  user  experience  is  directly  impacted.  \u25cf  HA  Indicator:  Application  can  continue  functioning  from  other  replicas  across  \nzones/nodes.\n \n \n3.  Pod  Eviction  (Soft  Disruption)  \u25cf  Use  Case:  Triggered  by  Kubernetes  itself  during  node  upgrades  or  scaling  down.  \u25cf  Why  It's  Important:  Ensures  graceful  termination  and  restart  elsewhere  without  user  \nimpact.\n \u25cf  Customer  Impact:  Should  be  zero  if  readiness/liveness  probes  and  PDBs  are  correctly  \nconfigured.\n \u25cf  HA  Indicator:  Rolling  disruption  does  not  take  down  the  whole  application.  \n \nHow  to  Know  If  It's  Highly  Available",
        "1.  Multiple  Replicas  Exist:  Confirmed  by  checking  kubectl  get  deploy and  seeing  >1  \nreplicas.\n 2.  Pods  Distributed  Across  Nodes/availability  zones:  Using  topologySpreadConstraints or  observing  pod  distribution  in  kubectl  get  pods  \n-o\n \nwide.  3.  Service  Uptime  Remains  Unaffected:  During  chaos  test,  verify  app  availability  (  \nsynthetic\n \nprobes,\n \nPrometheus\n \nalerts,\n \netc).\n 4.  Recovery  Is  Automatic:  No  manual  intervention  needed  to  restore  service.  5.  Krkn  Telemetry  Indicators:  End  of  run  data  includes  recovery  times,  pod  reschedule  \nlatency,\n \nand\n \nservice\n \ndowntime\n \nwhich\n \nare\n \nvital\n \nmetrics\n \nfor\n \nassessing\n \nHA.",
        "None \n None \nPod  Scenarios  using  Krkn  \nExample  Config  The  following  are  the  components  of  Kubernetes  for  which  a  basic  chaos  scenario  config  exists  \ntoday.\n \nkraken:    chaos_scenarios:      -  pod_disruption_scenarios:        -  path/to/scenario.yaml  \nCopy  You  can  then  create  the  scenario  file  with  the  following  contents:  \n#  yaml-language-server:  $schema=../plugin.schema.json  -  id:  kill-pods    config:      namespace_pattern:  ^kube-system$      label_selector:  k8s-app=kube-scheduler      krkn_pod_recovery_time:  120       \nCopy  Please  adjust  the  schema  reference  to  point  to  the  schema  file.  This  file  will  give  you  code  completion  and  documentation  for  the  available  options  in  your  IDE.  \nPod  Chaos  Scenarios  The  following  are  the  components  of  Kubernetes/OpenShift  for  which  a  basic  chaos  scenario  \nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario"
      ],
      "reference_answer": "The 'Single Pod Deletion' scenario specifically validates whether the ReplicaSet or Deployment automatically creates a replacement pod when an individual pod is unexpectedly deleted. This mechanism ensures continuous service even if a single pod crashes. For stateless applications, the expected recovery timing in this scenario is typically less than 10 seconds, a performance metric often observed and confirmed through Krkn telemetry output."    },
    {
      "user_input": "What is the primary concern regarding customer impact when 'Multiple Pods Deleted Simultaneously' occurs, and what architectural characteristic helps mitigate this impact to ensure high availability?",
      "generated_answer": "The primary concern regarding customer impact when 'Multiple Pods Deleted Simultaneously' occurs is that if all pods of a service fail, user experience is directly impacted. This can lead to a significant disruption in service. However, the architectural characteristic that helps mitigate this impact is having multiple replicas distributed across nodes/availability zones, which allows the application to continue functioning from other replicas.",
      "retrieved_context": [
        "Why  pod  scenarios  are  important:   \n \nUse  Cases  and  Importance  of  Pod-Level  Chaos  Scenarios  \n1.  Single  Pod  Deletion  \u25cf  Use  Case:  Simulates  unplanned  deletion  of  a  single  pod  \u25cf  Why  It's  Important:  Validates  whether  the  ReplicaSet  or  Deployment  automatically  \ncreates\n \na\n \nreplacement.\n \u25cf  Customer  Impact:  Ensures  continuous  service  even  if  a  pod  unexpectedly  crashes.  \u25cf  Recovery  Timing:  Typically  <10  seconds  for  stateless  apps  (seen  in  Krkn  telemetry  \noutput).\n \u25cf  HA  Indicator:  Pod  is  automatically  rescheduled  and  becomes  Ready  without  manual  \nintervention.\n  Kubectl  delete  pod  <pod-name> delete  pod  <pod-name>  Kubectl  get  pods  #  watch  for  new  pods \n2.  Multiple  Pods  Deleted  Simultaneously  \u25cf  Use  Case:  Simulates  a  larger  failure  event,  such  as  a  node  crash  or  AZ  outage.  \u25cf  Why  It's  Important:  Tests  whether  the  system  has  enough  resources  and  policies  to  \nrecover",
        "recover\n \ngracefully.\n \u25cf  Customer  Impact:  If  all  pods  of  a  service  fail,  user  experience  is  directly  impacted.  \u25cf  HA  Indicator:  Application  can  continue  functioning  from  other  replicas  across  \nzones/nodes.\n \n \n3.  Pod  Eviction  (Soft  Disruption)  \u25cf  Use  Case:  Triggered  by  Kubernetes  itself  during  node  upgrades  or  scaling  down.  \u25cf  Why  It's  Important:  Ensures  graceful  termination  and  restart  elsewhere  without  user  \nimpact.\n \u25cf  Customer  Impact:  Should  be  zero  if  readiness/liveness  probes  and  PDBs  are  correctly  \nconfigured.\n \u25cf  HA  Indicator:  Rolling  disruption  does  not  take  down  the  whole  application.  \n \nHow  to  Know  If  It's  Highly  Available",
        "1.  Multiple  Replicas  Exist:  Confirmed  by  checking  kubectl  get  deploy and  seeing  >1  \nreplicas.\n 2.  Pods  Distributed  Across  Nodes/availability  zones:  Using  topologySpreadConstraints or  observing  pod  distribution  in  kubectl  get  pods  \n-o\n \nwide.  3.  Service  Uptime  Remains  Unaffected:  During  chaos  test,  verify  app  availability  (  \nsynthetic\n \nprobes,\n \nPrometheus\n \nalerts,\n \netc).\n 4.  Recovery  Is  Automatic:  No  manual  intervention  needed  to  restore  service.  5.  Krkn  Telemetry  Indicators:  End  of  run  data  includes  recovery  times,  pod  reschedule  \nlatency,\n \nand\n \nservice\n \ndowntime\n \nwhich\n \nare\n \nvital\n \nmetrics\n \nfor\n \nassessing\n \nHA.",
        "config\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario \nKill  a  pod.  :heavy_check_mark:  \nEtcd Kills  a  single/multiple  etcd  replicas.  \n:heavy_check_mark:"
      ],
      "reference_answer": "The primary concern regarding customer impact when 'Multiple Pods Deleted Simultaneously' occurs is that if all pods of a service fail, the user experience is directly impacted, potentially leading to service unavailability. This significant impact can be mitigated and high availability ensured if the application is designed with redundancy, allowing it to continue functioning from other replicas that are distributed across different zones or nodes, preventing a single point of failure from taking down the entire service."    },
    {
      "user_input": "Describe the role of `topologySpreadConstraints` in achieving high availability and how their effective implementation can be verified using standard Kubernetes commands.",
      "generated_answer": "`topologySpreadConstraints` ensures high availability by spreading pods across nodes and availability zones to prevent single points of failure. Its effective implementation can be verified using `kubectl get pods -o wide` command, which shows pod distribution across the cluster. This verifies that topology constraints are properly applied.",
      "retrieved_context": [
        "Shell \nDISRUPTION_COUNT  Number  of  pods  to  disrupt  \n1  \nKILL_TIMEOUT  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \n180  \nEXPECTED_RECOVERY_TIME  Fails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \n120  \nNote  Set  NAMESPACE  environment  variable  to  openshift-.*  to  pick  and  disrupt  pods  randomly  in  \nopenshift\n \nsystem\n \nnamespaces,\n \nthe\n \nDAEMON_MODE\n \ncan\n \nalso\n \nbe\n \nenabled\n \nto\n \ndisrupt\n \nthe\n \npods\n \nevery\n \nx\n \nseconds\n \nin\n \nthe\n \nbackground\n \nto\n \ncheck\n \nthe\n \nreliability.\n \nNote  In  case  of  using  custom  metrics  profile  or  alerts  profile  when  CAPTURE_METRICS  or  \nENABLE_ALERTS\n \nis\n \nenabled,\n \nmount\n \nthe\n \nmetrics\n \nprofile\n \nfrom\n \nthe\n \nhost\n \non\n \nwhich\n \nthe\n \ncontainer\n \nis\n \nrun\n \nusing\n \npodman/docker\n \nunder\n \n/home/krkn/kraken/config/metrics-aggregated.yaml\n \nand\n \n/home/krkn/kraken/config/alerts.\n For  example:",
        "Shell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help",
        "config\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario \nKill  a  pod.  :heavy_check_mark:  \nEtcd Kills  a  single/multiple  etcd  replicas.  \n:heavy_check_mark:",
        "1.  Multiple  Replicas  Exist:  Confirmed  by  checking  kubectl  get  deploy and  seeing  >1  \nreplicas.\n 2.  Pods  Distributed  Across  Nodes/availability  zones:  Using  topologySpreadConstraints or  observing  pod  distribution  in  kubectl  get  pods  \n-o\n \nwide.  3.  Service  Uptime  Remains  Unaffected:  During  chaos  test,  verify  app  availability  (  \nsynthetic\n \nprobes,\n \nPrometheus\n \nalerts,\n \netc).\n 4.  Recovery  Is  Automatic:  No  manual  intervention  needed  to  restore  service.  5.  Krkn  Telemetry  Indicators:  End  of  run  data  includes  recovery  times,  pod  reschedule  \nlatency,\n \nand\n \nservice\n \ndowntime\n \nwhich\n \nare\n \nvital\n \nmetrics\n \nfor\n \nassessing\n \nHA."
      ],
      "reference_answer": "`topologySpreadConstraints` play a crucial role in achieving high availability by ensuring that pods are distributed evenly across different failure domains, such as nodes or availability zones. This prevents a single point of failure from impacting all replicas of an application. The effective implementation and resulting distribution can be observed using standard Kubernetes commands like `kubectl get pods -o wide`, which displays the node on which each pod is running, allowing an administrator to visually confirm the desired spread across the cluster's topology."    },
    {
      "user_input": "In the context of chaos engineering, what does 'Recovery Is Automatic' signify as a high availability indicator, and why is the absence of manual intervention considered critical for true HA?",
      "generated_answer": "\"Recovery Is Automatic\" signifies that the system can recover from a failure without manual intervention, ensuring high availability. The absence of manual intervention is critical for true HA because it indicates that the system can adapt and recover automatically in case of failures or disruptions. This enables continuous service delivery with minimal downtime.",
      "retrieved_context": [
        "1.  Multiple  Replicas  Exist:  Confirmed  by  checking  kubectl  get  deploy and  seeing  >1  \nreplicas.\n 2.  Pods  Distributed  Across  Nodes/availability  zones:  Using  topologySpreadConstraints or  observing  pod  distribution  in  kubectl  get  pods  \n-o\n \nwide.  3.  Service  Uptime  Remains  Unaffected:  During  chaos  test,  verify  app  availability  (  \nsynthetic\n \nprobes,\n \nPrometheus\n \nalerts,\n \netc).\n 4.  Recovery  Is  Automatic:  No  manual  intervention  needed  to  restore  service.  5.  Krkn  Telemetry  Indicators:  End  of  run  data  includes  recovery  times,  pod  reschedule  \nlatency,\n \nand\n \nservice\n \ndowntime\n \nwhich\n \nare\n \nvital\n \nmetrics\n \nfor\n \nassessing\n \nHA.",
        "recover\n \ngracefully.\n \u25cf  Customer  Impact:  If  all  pods  of  a  service  fail,  user  experience  is  directly  impacted.  \u25cf  HA  Indicator:  Application  can  continue  functioning  from  other  replicas  across  \nzones/nodes.\n \n \n3.  Pod  Eviction  (Soft  Disruption)  \u25cf  Use  Case:  Triggered  by  Kubernetes  itself  during  node  upgrades  or  scaling  down.  \u25cf  Why  It's  Important:  Ensures  graceful  termination  and  restart  elsewhere  without  user  \nimpact.\n \u25cf  Customer  Impact:  Should  be  zero  if  readiness/liveness  probes  and  PDBs  are  correctly  \nconfigured.\n \u25cf  HA  Indicator:  Rolling  disruption  does  not  take  down  the  whole  application.  \n \nHow  to  Know  If  It's  Highly  Available",
        "Why  pod  scenarios  are  important:   \n \nUse  Cases  and  Importance  of  Pod-Level  Chaos  Scenarios  \n1.  Single  Pod  Deletion  \u25cf  Use  Case:  Simulates  unplanned  deletion  of  a  single  pod  \u25cf  Why  It's  Important:  Validates  whether  the  ReplicaSet  or  Deployment  automatically  \ncreates\n \na\n \nreplacement.\n \u25cf  Customer  Impact:  Ensures  continuous  service  even  if  a  pod  unexpectedly  crashes.  \u25cf  Recovery  Timing:  Typically  <10  seconds  for  stateless  apps  (seen  in  Krkn  telemetry  \noutput).\n \u25cf  HA  Indicator:  Pod  is  automatically  rescheduled  and  becomes  Ready  without  manual  \nintervention.\n  Kubectl  delete  pod  <pod-name> delete  pod  <pod-name>  Kubectl  get  pods  #  watch  for  new  pods \n2.  Multiple  Pods  Deleted  Simultaneously  \u25cf  Use  Case:  Simulates  a  larger  failure  event,  such  as  a  node  crash  or  AZ  outage.  \u25cf  Why  It's  Important:  Tests  whether  the  system  has  enough  resources  and  policies  to  \nrecover",
        "Shell \nDISRUPTION_COUNT  Number  of  pods  to  disrupt  \n1  \nKILL_TIMEOUT  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \n180  \nEXPECTED_RECOVERY_TIME  Fails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \n120  \nNote  Set  NAMESPACE  environment  variable  to  openshift-.*  to  pick  and  disrupt  pods  randomly  in  \nopenshift\n \nsystem\n \nnamespaces,\n \nthe\n \nDAEMON_MODE\n \ncan\n \nalso\n \nbe\n \nenabled\n \nto\n \ndisrupt\n \nthe\n \npods\n \nevery\n \nx\n \nseconds\n \nin\n \nthe\n \nbackground\n \nto\n \ncheck\n \nthe\n \nreliability.\n \nNote  In  case  of  using  custom  metrics  profile  or  alerts  profile  when  CAPTURE_METRICS  or  \nENABLE_ALERTS\n \nis\n \nenabled,\n \nmount\n \nthe\n \nmetrics\n \nprofile\n \nfrom\n \nthe\n \nhost\n \non\n \nwhich\n \nthe\n \ncontainer\n \nis\n \nrun\n \nusing\n \npodman/docker\n \nunder\n \n/home/krkn/kraken/config/metrics-aggregated.yaml\n \nand\n \n/home/krkn/kraken/config/alerts.\n For  example:"
      ],
      "reference_answer": "In chaos engineering, 'Recovery Is Automatic' as a high availability indicator signifies that the system is designed to self-heal and restore service without any human intervention after a disruption. The absence of manual intervention is considered critical for true HA because it demonstrates the system's inherent resilience and automation capabilities. Manual intervention introduces delays, increases the potential for human error, and indicates a dependency on operational teams rather than robust, self-managing infrastructure, undermining the goal of continuous service availability."    },
    {
      "user_input": "What is the primary purpose of the `pod_disruption_scenarios` section within a Krkn configuration, and how is a specific scenario file referenced?",
      "generated_answer": "The primary purpose of the `pod_disruption_scenarios` section within a Krkn configuration is to define chaos scenarios that disrupt Kubernetes pods. A specific scenario file is referenced by its path, as shown in the example `path/to/scenario.yaml`. This file contains the configuration for the scenario, such as the namespace and label selector to target.",
      "retrieved_context": [
        "None \n None \nPod  Scenarios  using  Krkn  \nExample  Config  The  following  are  the  components  of  Kubernetes  for  which  a  basic  chaos  scenario  config  exists  \ntoday.\n \nkraken:    chaos_scenarios:      -  pod_disruption_scenarios:        -  path/to/scenario.yaml  \nCopy  You  can  then  create  the  scenario  file  with  the  following  contents:  \n#  yaml-language-server:  $schema=../plugin.schema.json  -  id:  kill-pods    config:      namespace_pattern:  ^kube-system$      label_selector:  k8s-app=kube-scheduler      krkn_pod_recovery_time:  120       \nCopy  Please  adjust  the  schema  reference  to  point  to  the  schema  file.  This  file  will  give  you  code  completion  and  documentation  for  the  available  options  in  your  IDE.  \nPod  Chaos  Scenarios  The  following  are  the  components  of  Kubernetes/OpenShift  for  which  a  basic  chaos  scenario  \nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario",
        "Shell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help",
        "Shell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy",
        "scenario/faults\n \nbeing\n \ninjected:\n Example  if  \u2013env-host  is  used:  \nexport  <parameter_name>=<value>  \nOR  on  the  command  line  like  example:  \n-e  <VARIABLE>=<value>   \nSee  list  of  variables  that  apply  to  all  scenarios  here that  can  be  used/set  in  addition  to  these  scenario  specific  variables  Parameter  Description  Default  \nNAMESPACE  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nopenshift-.*  \nPOD_LABEL  Label  of  the  pod(s)  to  target  \n\"\"  \nNAME_PATTERN  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \n.*"
      ],
      "reference_answer": "The `pod_disruption_scenarios` section in a Krkn configuration is used to define and include specific pod chaos scenarios. A scenario file is referenced by providing its `path/to/scenario.yaml` within this section, allowing Krkn to execute the disruption defined in that file."    },
    {
      "user_input": "How can a user leverage the provided schema file to enhance their experience when creating a Krkn scenario configuration in an IDE?",
      "generated_answer": "You can leverage the provided schema file by referencing it in your scenario configuration file with `# yaml-language-server: $schema=../plugin.schema.json`. This will enable code completion and documentation for available options in your IDE.",
      "retrieved_context": [
        "None \n None \nPod  Scenarios  using  Krkn  \nExample  Config  The  following  are  the  components  of  Kubernetes  for  which  a  basic  chaos  scenario  config  exists  \ntoday.\n \nkraken:    chaos_scenarios:      -  pod_disruption_scenarios:        -  path/to/scenario.yaml  \nCopy  You  can  then  create  the  scenario  file  with  the  following  contents:  \n#  yaml-language-server:  $schema=../plugin.schema.json  -  id:  kill-pods    config:      namespace_pattern:  ^kube-system$      label_selector:  k8s-app=kube-scheduler      krkn_pod_recovery_time:  120       \nCopy  Please  adjust  the  schema  reference  to  point  to  the  schema  file.  This  file  will  give  you  code  completion  and  documentation  for  the  available  options  in  your  IDE.  \nPod  Chaos  Scenarios  The  following  are  the  components  of  Kubernetes/OpenShift  for  which  a  basic  chaos  scenario  \nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario",
        "Shell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help",
        "Shell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy",
        "scenario/faults\n \nbeing\n \ninjected:\n Example  if  \u2013env-host  is  used:  \nexport  <parameter_name>=<value>  \nOR  on  the  command  line  like  example:  \n-e  <VARIABLE>=<value>   \nSee  list  of  variables  that  apply  to  all  scenarios  here that  can  be  used/set  in  addition  to  these  scenario  specific  variables  Parameter  Description  Default  \nNAMESPACE  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nopenshift-.*  \nPOD_LABEL  Label  of  the  pod(s)  to  target  \n\"\"  \nNAME_PATTERN  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \n.*"
      ],
      "reference_answer": "Users can enhance their experience by adjusting the schema reference in their scenario file to point to the `plugin.schema.json` file (e.g., `yaml-language-server: $schema=../plugin.schema.json`). This integration provides valuable features like code completion and documentation for available options directly within their IDE."    },
    {
      "user_input": "In a kill-pods chaos scenario targeting Kubernetes components, which component is commonly disrupted and how are its pods typically selected?",
      "generated_answer": "In a kill-pods chaos scenario targeting Kubernetes components, the commonly disrupted component is the kube-scheduler. Its pods are typically selected based on a label selector \"k8s-app=kube-scheduler\" in the namespace \"kube-system\". The disruption time is set to 120 seconds.",
      "retrieved_context": [
        "None \n None \nPod  Scenarios  using  Krkn  \nExample  Config  The  following  are  the  components  of  Kubernetes  for  which  a  basic  chaos  scenario  config  exists  \ntoday.\n \nkraken:    chaos_scenarios:      -  pod_disruption_scenarios:        -  path/to/scenario.yaml  \nCopy  You  can  then  create  the  scenario  file  with  the  following  contents:  \n#  yaml-language-server:  $schema=../plugin.schema.json  -  id:  kill-pods    config:      namespace_pattern:  ^kube-system$      label_selector:  k8s-app=kube-scheduler      krkn_pod_recovery_time:  120       \nCopy  Please  adjust  the  schema  reference  to  point  to  the  schema  file.  This  file  will  give  you  code  completion  and  documentation  for  the  available  options  in  your  IDE.  \nPod  Chaos  Scenarios  The  following  are  the  components  of  Kubernetes/OpenShift  for  which  a  basic  chaos  scenario  \nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario",
        "Shell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help",
        "Shell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy",
        "config\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario \nKill  a  pod.  :heavy_check_mark:  \nEtcd Kills  a  single/multiple  etcd  replicas.  \n:heavy_check_mark:"
      ],
      "reference_answer": "The `kill-pods` scenario targets the `kube-scheduler` component. It selects pods by looking for those within the `kube-system` namespace (specified by `namespace_pattern: ^kube-system$`) that also possess the label `k8s-app=kube-scheduler` (specified by `label_selector`)."    },
    {
      "user_input": "In a Krkn pod disruption scenario, what does the `krkn_pod_recovery_time` parameter control, and what is a typical value for it?",
      "generated_answer": "The `krkn_pod_recovery_time` parameter controls the time allowed for a pod to recover after disruption. A typical value for it is 120 seconds, as shown in the example scenario configuration file. This means that if the disrupted pod does not recover within 2 minutes, the test will fail.",
      "retrieved_context": [
        "Shell \nDISRUPTION_COUNT  Number  of  pods  to  disrupt  \n1  \nKILL_TIMEOUT  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \n180  \nEXPECTED_RECOVERY_TIME  Fails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \n120  \nNote  Set  NAMESPACE  environment  variable  to  openshift-.*  to  pick  and  disrupt  pods  randomly  in  \nopenshift\n \nsystem\n \nnamespaces,\n \nthe\n \nDAEMON_MODE\n \ncan\n \nalso\n \nbe\n \nenabled\n \nto\n \ndisrupt\n \nthe\n \npods\n \nevery\n \nx\n \nseconds\n \nin\n \nthe\n \nbackground\n \nto\n \ncheck\n \nthe\n \nreliability.\n \nNote  In  case  of  using  custom  metrics  profile  or  alerts  profile  when  CAPTURE_METRICS  or  \nENABLE_ALERTS\n \nis\n \nenabled,\n \nmount\n \nthe\n \nmetrics\n \nprofile\n \nfrom\n \nthe\n \nhost\n \non\n \nwhich\n \nthe\n \ncontainer\n \nis\n \nrun\n \nusing\n \npodman/docker\n \nunder\n \n/home/krkn/kraken/config/metrics-aggregated.yaml\n \nand\n \n/home/krkn/kraken/config/alerts.\n For  example:",
        "Shell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help",
        "None \n None \nPod  Scenarios  using  Krkn  \nExample  Config  The  following  are  the  components  of  Kubernetes  for  which  a  basic  chaos  scenario  config  exists  \ntoday.\n \nkraken:    chaos_scenarios:      -  pod_disruption_scenarios:        -  path/to/scenario.yaml  \nCopy  You  can  then  create  the  scenario  file  with  the  following  contents:  \n#  yaml-language-server:  $schema=../plugin.schema.json  -  id:  kill-pods    config:      namespace_pattern:  ^kube-system$      label_selector:  k8s-app=kube-scheduler      krkn_pod_recovery_time:  120       \nCopy  Please  adjust  the  schema  reference  to  point  to  the  schema  file.  This  file  will  give  you  code  completion  and  documentation  for  the  available  options  in  your  IDE.  \nPod  Chaos  Scenarios  The  following  are  the  components  of  Kubernetes/OpenShift  for  which  a  basic  chaos  scenario  \nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario",
        "Shell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy"
      ],
      "reference_answer": "The `krkn_pod_recovery_time` parameter specifies the duration, in seconds, that Krkn will wait for a disrupted pod to recover. A commonly used value is `120`, which represents a 120\u2011second recovery period."    },
    {
      "user_input": "Beyond a general 'basic pod scenario,' what are some of the critical Kubernetes or OpenShift components for which Krkn offers pre-defined chaos scenarios, and are they currently functional?",
      "generated_answer": "Krkn offers pre-defined chaos scenarios for several critical Kubernetes or OpenShift components, including pod disruption scenarios. The available components include namespace patterns, label selectors, and pods in specific namespaces. These components are currently functional.",
      "retrieved_context": [
        "None \n None \nPod  Scenarios  using  Krkn  \nExample  Config  The  following  are  the  components  of  Kubernetes  for  which  a  basic  chaos  scenario  config  exists  \ntoday.\n \nkraken:    chaos_scenarios:      -  pod_disruption_scenarios:        -  path/to/scenario.yaml  \nCopy  You  can  then  create  the  scenario  file  with  the  following  contents:  \n#  yaml-language-server:  $schema=../plugin.schema.json  -  id:  kill-pods    config:      namespace_pattern:  ^kube-system$      label_selector:  k8s-app=kube-scheduler      krkn_pod_recovery_time:  120       \nCopy  Please  adjust  the  schema  reference  to  point  to  the  schema  file.  This  file  will  give  you  code  completion  and  documentation  for  the  available  options  in  your  IDE.  \nPod  Chaos  Scenarios  The  following  are  the  components  of  Kubernetes/OpenShift  for  which  a  basic  chaos  scenario  \nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario",
        "Shell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help",
        "Shell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy",
        "Shell \nDISRUPTION_COUNT  Number  of  pods  to  disrupt  \n1  \nKILL_TIMEOUT  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \n180  \nEXPECTED_RECOVERY_TIME  Fails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \n120  \nNote  Set  NAMESPACE  environment  variable  to  openshift-.*  to  pick  and  disrupt  pods  randomly  in  \nopenshift\n \nsystem\n \nnamespaces,\n \nthe\n \nDAEMON_MODE\n \ncan\n \nalso\n \nbe\n \nenabled\n \nto\n \ndisrupt\n \nthe\n \npods\n \nevery\n \nx\n \nseconds\n \nin\n \nthe\n \nbackground\n \nto\n \ncheck\n \nthe\n \nreliability.\n \nNote  In  case  of  using  custom  metrics  profile  or  alerts  profile  when  CAPTURE_METRICS  or  \nENABLE_ALERTS\n \nis\n \nenabled,\n \nmount\n \nthe\n \nmetrics\n \nprofile\n \nfrom\n \nthe\n \nhost\n \non\n \nwhich\n \nthe\n \ncontainer\n \nis\n \nrun\n \nusing\n \npodman/docker\n \nunder\n \n/home/krkn/kraken/config/metrics-aggregated.yaml\n \nand\n \n/home/krkn/kraken/config/alerts.\n For  example:"
      ],
      "reference_answer": "Krkn offers pre-defined chaos scenarios for critical components such as Etcd, Kube ApiServer, ApiServer, Prometheus, and random pods running in OpenShift system namespaces. These scenarios are listed as functional in the Krkn documentation."    },
    {
      "user_input": "If a user wanted to specifically target the Kubernetes API server for a chaos experiment, which Krkn scenario would be appropriate, and what action would it perform?",
      "generated_answer": "To target the Kubernetes API server for a chaos experiment, the \"Kube ApiServer Kills\" scenario is appropriate. This scenario kills one or multiple kube-apiserver replicas.",
      "retrieved_context": [
        "None \n None \nPod  Scenarios  using  Krkn  \nExample  Config  The  following  are  the  components  of  Kubernetes  for  which  a  basic  chaos  scenario  config  exists  \ntoday.\n \nkraken:    chaos_scenarios:      -  pod_disruption_scenarios:        -  path/to/scenario.yaml  \nCopy  You  can  then  create  the  scenario  file  with  the  following  contents:  \n#  yaml-language-server:  $schema=../plugin.schema.json  -  id:  kill-pods    config:      namespace_pattern:  ^kube-system$      label_selector:  k8s-app=kube-scheduler      krkn_pod_recovery_time:  120       \nCopy  Please  adjust  the  schema  reference  to  point  to  the  schema  file.  This  file  will  give  you  code  completion  and  documentation  for  the  available  options  in  your  IDE.  \nPod  Chaos  Scenarios  The  following  are  the  components  of  Kubernetes/OpenShift  for  which  a  basic  chaos  scenario  \nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario",
        "Shell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help",
        "Shell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy",
        "Kube  ApiServer Kills  a  single/multiple  kube-apiserver  replicas.  \n:heavy_check_mark:  \nApiServer Kills  a  single/multiple  apiserver  replicas.  \n:heavy_check_mark:  \nPrometheus Kills  a  single/multiple  prometheus  replicas.  \n:heavy_check_mark:  \nOpenShift  System  Pods \nKills  random  pods  running  in  the  OpenShift  system  namespaces.  \n:heavy_check_mark:"
      ],
      "reference_answer": "To target the Kubernetes API server, the 'Kube ApiServer' scenario would be appropriate. This scenario is designed to kill either a single or multiple replicas of the kube-apiserver component."    },
    {
      "user_input": "How does the 'OpenShift System Pods' chaos scenario differ in its targeting approach compared to component-specific scenarios like 'Etcd' or 'Prometheus'?",
      "generated_answer": "The 'OpenShift System Pods' chaos scenario differs from component-specific scenarios like 'Etcd' or 'Prometheus' in its targeting approach. It uses a more general targeting method, allowing for the disruption of pods across the entire OpenShift cluster based on namespace patterns and label selectors. This is in contrast to more specific targeting methods used by component-specific scenarios.",
      "retrieved_context": [
        "None \n None \nPod  Scenarios  using  Krkn  \nExample  Config  The  following  are  the  components  of  Kubernetes  for  which  a  basic  chaos  scenario  config  exists  \ntoday.\n \nkraken:    chaos_scenarios:      -  pod_disruption_scenarios:        -  path/to/scenario.yaml  \nCopy  You  can  then  create  the  scenario  file  with  the  following  contents:  \n#  yaml-language-server:  $schema=../plugin.schema.json  -  id:  kill-pods    config:      namespace_pattern:  ^kube-system$      label_selector:  k8s-app=kube-scheduler      krkn_pod_recovery_time:  120       \nCopy  Please  adjust  the  schema  reference  to  point  to  the  schema  file.  This  file  will  give  you  code  completion  and  documentation  for  the  available  options  in  your  IDE.  \nPod  Chaos  Scenarios  The  following  are  the  components  of  Kubernetes/OpenShift  for  which  a  basic  chaos  scenario  \nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario",
        "Shell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help",
        "Shell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy",
        "scenario/faults\n \nbeing\n \ninjected:\n Example  if  \u2013env-host  is  used:  \nexport  <parameter_name>=<value>  \nOR  on  the  command  line  like  example:  \n-e  <VARIABLE>=<value>   \nSee  list  of  variables  that  apply  to  all  scenarios  here that  can  be  used/set  in  addition  to  these  scenario  specific  variables  Parameter  Description  Default  \nNAMESPACE  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nopenshift-.*  \nPOD_LABEL  Label  of  the  pod(s)  to  target  \n\"\"  \nNAME_PATTERN  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \n.*"
      ],
      "reference_answer": "The 'OpenShift System Pods' scenario targets random pods running across various OpenShift system namespaces, providing a broader, less specific disruption. In contrast, component-specific scenarios like 'Etcd' or 'Prometheus' precisely target replicas of those named components, focusing disruption on a particular service."    },
    {
      "user_input": "What is the purpose of the `id` field within a Krkn scenario configuration?",
      "generated_answer": "The `id` field within a Krkn scenario configuration is used to uniquely identify the scenario, and it appears in the provided example as \"kill-pods\".",
      "retrieved_context": [
        "Shell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help",
        "None \n None \nPod  Scenarios  using  Krkn  \nExample  Config  The  following  are  the  components  of  Kubernetes  for  which  a  basic  chaos  scenario  config  exists  \ntoday.\n \nkraken:    chaos_scenarios:      -  pod_disruption_scenarios:        -  path/to/scenario.yaml  \nCopy  You  can  then  create  the  scenario  file  with  the  following  contents:  \n#  yaml-language-server:  $schema=../plugin.schema.json  -  id:  kill-pods    config:      namespace_pattern:  ^kube-system$      label_selector:  k8s-app=kube-scheduler      krkn_pod_recovery_time:  120       \nCopy  Please  adjust  the  schema  reference  to  point  to  the  schema  file.  This  file  will  give  you  code  completion  and  documentation  for  the  available  options  in  your  IDE.  \nPod  Chaos  Scenarios  The  following  are  the  components  of  Kubernetes/OpenShift  for  which  a  basic  chaos  scenario  \nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario",
        "scenario/faults\n \nbeing\n \ninjected:\n Example  if  \u2013env-host  is  used:  \nexport  <parameter_name>=<value>  \nOR  on  the  command  line  like  example:  \n-e  <VARIABLE>=<value>   \nSee  list  of  variables  that  apply  to  all  scenarios  here that  can  be  used/set  in  addition  to  these  scenario  specific  variables  Parameter  Description  Default  \nNAMESPACE  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nopenshift-.*  \nPOD_LABEL  Label  of  the  pod(s)  to  target  \n\"\"  \nNAME_PATTERN  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \n.*",
        "Shell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy"
      ],
      "reference_answer": "The `id` field, serves as a unique identifier for a specific chaos scenario defined within the Krkn configuration file. It provides a distinct name for the scenario being executed."    },
    {
      "user_input": "Can the `kill-pods` scenario be configured to disrupt pods outside of the `kube-system` namespace?",
      "generated_answer": "You can configure the `kill-pods` scenario to disrupt pods outside of the `kube-system` namespace by setting the `NAMESPACE` environment variable to a different namespace, such as `openshift-*`. You can also use the `--namespace` parameter with `krknctl run pod-scenarios` to specify a different target namespace.",
      "retrieved_context": [
        "Shell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help",
        "Kube  ApiServer Kills  a  single/multiple  kube-apiserver  replicas.  \n:heavy_check_mark:  \nApiServer Kills  a  single/multiple  apiserver  replicas.  \n:heavy_check_mark:  \nPrometheus Kills  a  single/multiple  prometheus  replicas.  \n:heavy_check_mark:  \nOpenShift  System  Pods \nKills  random  pods  running  in  the  OpenShift  system  namespaces.  \n:heavy_check_mark:",
        "Shell \nDISRUPTION_COUNT  Number  of  pods  to  disrupt  \n1  \nKILL_TIMEOUT  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \n180  \nEXPECTED_RECOVERY_TIME  Fails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \n120  \nNote  Set  NAMESPACE  environment  variable  to  openshift-.*  to  pick  and  disrupt  pods  randomly  in  \nopenshift\n \nsystem\n \nnamespaces,\n \nthe\n \nDAEMON_MODE\n \ncan\n \nalso\n \nbe\n \nenabled\n \nto\n \ndisrupt\n \nthe\n \npods\n \nevery\n \nx\n \nseconds\n \nin\n \nthe\n \nbackground\n \nto\n \ncheck\n \nthe\n \nreliability.\n \nNote  In  case  of  using  custom  metrics  profile  or  alerts  profile  when  CAPTURE_METRICS  or  \nENABLE_ALERTS\n \nis\n \nenabled,\n \nmount\n \nthe\n \nmetrics\n \nprofile\n \nfrom\n \nthe\n \nhost\n \non\n \nwhich\n \nthe\n \ncontainer\n \nis\n \nrun\n \nusing\n \npodman/docker\n \nunder\n \n/home/krkn/kraken/config/metrics-aggregated.yaml\n \nand\n \n/home/krkn/kraken/config/alerts.\n For  example:",
        "Shell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy"
      ],
      "reference_answer": "By default, the `kill-pods` scenario is restricted to the `kube-system` namespace through the `namespace_pattern: ^kube-system$` setting. However, this setting can be modified to target pods in other namespaces if desired."    },
    {
      "user_input": "Describe the hierarchical structure for defining chaos scenarios within the top-level `kraken` configuration block?",
      "generated_answer": "The hierarchical structure for defining chaos scenarios within the top-level `kraken` configuration block is as follows:\n- `chaos_scenarios`\n  - `pod_disruption_scenarios`\n    - path/to/scenario.yaml\nIn this structure, `chaos_scenarios` is a list of disruption scenarios, and `pod_disruption_scenarios` is a specific type of scenario that disrupts pods.",
      "retrieved_context": [
        "None \n None \nPod  Scenarios  using  Krkn  \nExample  Config  The  following  are  the  components  of  Kubernetes  for  which  a  basic  chaos  scenario  config  exists  \ntoday.\n \nkraken:    chaos_scenarios:      -  pod_disruption_scenarios:        -  path/to/scenario.yaml  \nCopy  You  can  then  create  the  scenario  file  with  the  following  contents:  \n#  yaml-language-server:  $schema=../plugin.schema.json  -  id:  kill-pods    config:      namespace_pattern:  ^kube-system$      label_selector:  k8s-app=kube-scheduler      krkn_pod_recovery_time:  120       \nCopy  Please  adjust  the  schema  reference  to  point  to  the  schema  file.  This  file  will  give  you  code  completion  and  documentation  for  the  available  options  in  your  IDE.  \nPod  Chaos  Scenarios  The  following  are  the  components  of  Kubernetes/OpenShift  for  which  a  basic  chaos  scenario  \nconfig\n \nexists\n \ntoday.\n Component  Description  Working  \nBasic  pod  scenario",
        "Shell \n Shell \nPod  Scenarios  using  Krknctl  \nkrknctl  run  pod-scenarios  (optional:  --<parameter>:<value>  )  \nCopy  Can  also  set  any  global  variable  listed  here Scenario  specific  parameters:  Parameter  Description  Type  Default  \n--namespace  Targeted  namespace  in  the  cluster  (  supports  regex  )  \nstring  openshift-*  \n--pod-label  Label  of  the  pod(s)  to  target  ex.  \u201capp=test\u201d  \nstring   \n--name-pattern  Regex  pattern  to  match  the  pods  in  NAMESPACE  when  POD_LABEL  is  not  specified  \nstring  .*  \n--disruption-count  Number  of  pods  to  disrupt  number  1  \n--kill-timeout  Timeout  to  wait  for  the  target  pod(s)  to  be  removed  in  seconds  \nnumber  180  \n--expected-recovery-time  \nFails  if  the  pod  disrupted  do  not  recover  within  the  timeout  set  \nnumber  120  \nTo  see  all  available  scenario  options  \nkrknctl  run  pod-scenarios  --help",
        "Shell \n Shell \nPod  Scenarios  using  Krkn-hub  \nThis  scenario  disrupts  the  pods  matching  the  label  in  the  specified  namespace  on  a  \nKubernetes/OpenShift\n \ncluster.\n \nRun  If  enabling  Cerberus to  monitor  the  cluster  and  pass/fail  the  scenario  post  chaos,  refer  docs.  Make  sure  to  start  it  before  injecting  the  chaos  and  set  CERBERUS_ENABLED  environment  \nvariable\n \nfor\n \nthe\n \nchaos\n \ninjection\n \ncontainer\n \nto\n \nautoconnect.\n \n$  podman  run  --name=<container_name>  --net=host  --env-host=true  -v  \n<path-to-kube-config>:/home/krkn/.kube/config:Z\n \n-d\n \ncontainers.krkn-chaos.dev/krkn-chaos/krkn-hub:pod-scenarios\n $  podman  logs  -f  <container_name  or  container_id>  #  Streams  Kraken  logs  $  podman  inspect  <container-name  or  container-id>  --format  \"{{.State.ExitCode}}\"  #  \nOutputs\n \nexit\n \ncode\n \nwhich\n \ncan\n \nconsidered\n \nas\n \npass/fail\n \nfor\n \nthe\n \nscenario\n \nCopy",
        "1.  Multiple  Replicas  Exist:  Confirmed  by  checking  kubectl  get  deploy and  seeing  >1  \nreplicas.\n 2.  Pods  Distributed  Across  Nodes/availability  zones:  Using  topologySpreadConstraints or  observing  pod  distribution  in  kubectl  get  pods  \n-o\n \nwide.  3.  Service  Uptime  Remains  Unaffected:  During  chaos  test,  verify  app  availability  (  \nsynthetic\n \nprobes,\n \nPrometheus\n \nalerts,\n \netc).\n 4.  Recovery  Is  Automatic:  No  manual  intervention  needed  to  restore  service.  5.  Krkn  Telemetry  Indicators:  End  of  run  data  includes  recovery  times,  pod  reschedule  \nlatency,\n \nand\n \nservice\n \ndowntime\n \nwhich\n \nare\n \nvital\n \nmetrics\n \nfor\n \nassessing\n \nHA."
      ],
      "reference_answer": "Within the `kraken` configuration block, chaos scenarios are organized under the `chaos_scenarios` key. This key contains a list, where each item is a `pod_disruption_scenarios` entry, which in turn specifies the `path/to/scenario.yaml` file containing the detailed configuration for a particular pod disruption."    }
  ],
  "email": "user_email@example.com"
}